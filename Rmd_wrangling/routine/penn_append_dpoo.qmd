---
title: "penn_append"
format: html
editor: source
---

## Load Packages

```{r}
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}

# librarian downloads, if not already downloaded, and reads in needed packages
librarian::shelf(tidyverse, dbplyr, here, janitor, lubridate, RPostgres, stringr, DBI, parsedate, uuid, hms)
```

## Point to data directory

Keeping data in a central directory. Naming convention uses download date to distinguish batches.

```{r}
ddir = Sys.getenv("data_dir")  # data directory
wddir = here(ddir, "fulcrum", 'penn', '2024-09-13') # working data directory

```

# 0 - Data Plan

## Goals

- Integrate batches of Penn survey data with other RIBBiTR data (including other Penn data) for combined analysis
- Compare with existing data to avoid duplicating, and facilitate automated updating
- Quality control for red flag data (potential or known issues)
- Upload to Database in transaction
- log transaction

## Data chains (someday we can automate this... *sigh*)

- aural / survey / visit / site / region / location
- capture / survey / visit / site / region / location
- ves / survey / visit / site / region / location

# 1 - Import data

## DB Connection

```{r}
# can we run this in a withr statement, instead of leaving the connection hanging?

tryCatch({
    print("Connecting to Database…")
    connection <- dbConnect(drv = dbDriver("Postgres"),
                 dbname = Sys.getenv("aws_dbname"),
                 host = Sys.getenv("aws_host"),
                 port = Sys.getenv("aws_port"),
                 user = Sys.getenv("aws_user"),
                 password = Sys.getenv("aws_password"),
                 timezone=NULL)
    print("Database Connected!")
    },
    error=function(cond) {
            print("Unable to connect to Database.")
    })

dbExecute(connection, "set search_path to survey_data")
```
## Pull metadata from database
```{r}
metadata_columns = tbl(connection, "metadata_columns")

```

## Define functions

```{r}

pkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           key_type == "PK") %>%
    pull(column_name)
}

fkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           key_type == "FK") %>%
    pull(column_name)
}

nkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           natural_key) %>%
    pull(column_name)
}

UUIDgenerate_if_NA = function(str) {
  if (is.na(str)) {
    return(UUIDgenerate())
  } else {
    return(str)
  }
}

# # in dev, not using currently
# chains = function(table, metadata_columns) {
#   chains = list()
#   key_list = list()
#   tab_list = list()
#   
#   tray = list()
#   
#   tab_list = append(tab_list, table)
#   
#   current_table = table
#   
#   fkey = metadata_columns %>%
#     filter(table_name == current_table,
#            key_type == "FK") %>%
#     pull(column_name)
#   
#   if (length(fkey) > 1) {
#     for (ff in fkey) {
#       # handle multiple chains
#     }
#   }
#   
#   parent_table = metadata_columns %>%
#     filter(column_name == fkey,
#            key_type == "PK") %>%
#     pull(table_name)
#   
#   tab_list = append(tab_list, parent_table)
#   key_list = append(key_list, fkey)
#   
# }

```

## Pull dependent tables for each data chain

# use naming convention "db\_" to distinguish the source

```{r}
# pull relevant chain tables from DB
db_aural = tbl(connection, "aural")
db_capture = tbl(connection, "capture")
db_ves = tbl(connection, "ves")
db_survey = tbl(connection, "survey")
db_visit = tbl(connection, "visit")
db_site = tbl(connection, "site")
db_region = tbl(connection, "region")
db_location = tbl(connection, "location")
```

## Load most recent CSV Exports

- read in csv files
- drop unnecessary fulcrum columns
- clean column names
- drop/mutate specific columns

# use naming convention "raw\_" to distinguish the source

```{r}

# Fulcrum columns to drop. Best practice to drop by name
 to_drop = c(
   "created_at",
   "updated_at",
   "created_by",
   "updated_by",
   "system_created_at",
   "system_updated_at",
   "version",
   "status",
   "project",
   "assigned_to",
   "latitude" ,
   "longitude",
   "geometry"
 )

null_columns = function(dataframe) {
  filtered = dataframe %>%
    select(where(~ all(is.na(.)))) %>%
    colnames()
}


raw_survey_info <- read_csv(here(wddir, "1_penn_surveyinformation",
                             "1_penn_surveyinformation.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>% 
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         survey_time = str_to_lower(survey_time)) %>%
  rename(visit_comments = sampling_event_comments)

raw_survey_acoustic <- read_csv(here(wddir, "2_penn_acousticsurvey",
                                 "2_penn_acousticsurvey.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>% 
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         survey_time = str_to_lower(survey_time)) %>%
  mutate(detection_type = "aural")

raw_acoustic_obs <- read_csv(here(wddir, "2_penn_acousticsurvey",
                              "2_penn_acousticsurvey_acoustic_survey.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>%
  mutate(detection_type = "aural")

# don't load eDNA data
# raw_survey_edna <- read_csv(here(wddir, "3_penn_ednasurvey",
#                              "3_penn_ednasurvey.csv")) %>%
#   select(!any_of(to_drop)) %>%
#   clean_names()
# 
# raw_edna_obs_col <- read_csv(here(wddir, "3_penn_ednasurvey",
#                               "3_penn_ednasurvey_edna_collection.csv")) %>%
#   select(!any_of(to_drop)) %>%
#   clean_names()
# 
# raw_edna_obs_filt <- read_csv(here(wddir, "3_penn_ednasurvey",
#                                "3_penn_ednasurvey_edna_collection_edna_filtering.csv")) %>%
#   select(!any_of(to_drop)) %>%
#   clean_names()

raw_survey_ves <- read_csv(here(wddir, "4_penn_visualencountersurvey",
                            "4_penn_visualencountersurvey.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>% 
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         survey_time = str_to_lower(survey_time)) %>%
  mutate(detection_type = "visual")

raw_ves_obs <- read_csv(here(wddir, "4_penn_visualencountersurvey", 
                         "4_penn_visualencountersurvey_visual_encounter_information.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>%
  mutate(detection_type = "visual")

raw_survey_capture <- read_csv(here(wddir, "5_penn_capturesurvey",
                                "5_penn_capturesurvey.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>% 
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         survey_time = str_to_lower(survey_time)) %>%
  mutate(detection_type = "capture")

raw_capture_obs <- read_csv(here(wddir, "5_penn_capturesurvey", 
                             "5_penn_capturesurvey_captured_amphibian_information.csv")) %>%
  select(!any_of(to_drop)) %>%
  select(!"capture_status") %>% # capture status: was this individual successfully captured?
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names() %>%
  mutate(detection_type = "capture")

raw_samp_proces <- read_csv(here(wddir, "6_penn_sampleprocessing",
                             "6_penn_sampleprocessing.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names()

raw_samp_procces_obs <- read_csv(here(wddir, "6_penn_sampleprocessing",
                                  "6_penn_sampleprocessing_amphibian_capture_survey_collections.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names()

raw_cmr <- read_csv(here(wddir, "supp_penn_cmrids",
                     "supp_penn_cmrids.csv")) %>%
  select(!any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na)) %>%  # drop any rows all null
  clean_names()

```

# 2 - Drop irrelevant: Early QA

```{r}

# check null columns
(null_columns(raw_survey_info))
(null_columns(raw_survey_acoustic))
(null_columns(raw_acoustic_obs))
(null_columns(raw_survey_ves))
(null_columns(raw_ves_obs))
(null_columns(raw_survey_capture))
(null_columns(raw_capture_obs))
(null_columns(raw_samp_proces))
(null_columns(raw_samp_procces_obs))
(null_columns(raw_cmr))

# check duplicated rows
any(duplicated(raw_survey_info))
any(duplicated(raw_survey_acoustic))
any(duplicated(raw_acoustic_obs))
any(duplicated(raw_survey_ves))
any(duplicated(raw_ves_obs))
any(duplicated(raw_survey_capture))
any(duplicated(raw_capture_obs))
any(duplicated(raw_samp_proces))
any(duplicated(raw_samp_procces_obs))
any(duplicated(raw_cmr))

```

# 3 - Fix struvtural issues

- Renaming columns – descriptive and well formatted. Rename them well from the beginning, so you don’t have to do it again
- Split or concatenate related columns
- Convert to accurate data types
- NA formatting

```{r}

```

## Merge unique visits include site

### Merge all site visits

- pull unique visits from survey_info, survey_acoustic, survey_capture, survey_edna, and survey_ves
- spread site_info comments across all corresponding visits

```{r}

# site info comments
temp_visit_comments <- raw_survey_info %>% 
  select(site, date, visit_comments)

mid_visit <- bind_rows(raw_survey_info, raw_survey_acoustic, raw_survey_capture, raw_survey_ves) %>% 
  select(date, site, survey_time) %>%
  filter(!is.na(site)) %>%  # drop observations with NA site
  group_by(date, site) %>%
  mutate(temp_id = cur_group_id()) %>% 
  filter(!duplicated(temp_id)) %>%
  left_join(temp_visit_comments, by = c("site", "date")) %>% # merge comments across all visits
  select(!temp_id) %>% 
  ungroup()

```

### Pull site_id f.key (uuid) from site table of DB

```{r}

site_key = db_site %>%
  select(site, site_id) %>%
  collect()

```

### Coalesce with DB
- Join with site_id
- Join with visit_db
- create visit_id (uuid) on visit table where doesnt yet exist
- coalesce comments, prioritizing new data

```{r}

# confirm visit does not already exist
final_visit = mid_visit %>%
  left_join(site_key, by = "site") %>%
  left_join(db_visit %>% collect(), by = nkey("visit", metadata_columns)) %>%
  mutate(visit_id = map_chr(visit_id, ~ UUIDgenerate_if_NA(.))) %>% # generate UUID only if not already present
  mutate(visit_comments = coalesce(visit_comments.x, visit_comments.y)) %>% # prioritize new site comments in case updated
  select(-site,
         -visit_comments.x,
         -visit_comments.y)

# test to make sure column names are the same, nothing is missing

# test to make sure datatypes are good

# handle possible new sites
if (any(is.na(final_visit$site_id))) {
  warningCondition("New or unknown sites found in incoming data. Troubleshoot.")
  # do we want this new site in the database?
  #   yes: generate new uuid and update db site table.
  #   no: drop and incorporate relevant filter to prevent recurrence
}

```

### Append to visit table

```{r}


warningCondition("Visit append commented out. Rewrite at end as single transaction.")
# dbAppendTable(connection, "visit", fin_visit)  # append at end in transaction
  

```

## Merge all survey data into common survey table

### Massage Survey data date and survey_time

```{r}

mid_surv_capture <- raw_survey_info %>%
  left_join(raw_survey_capture, by = c("site", "date")) %>%
  select(!c(fulcrum_id.x,
            fulcrum_id.y,
            observer,
            observer_other,
            site_other.x,
            site_other.y,
            start_time.x,
            end_time.x,
            survey_time.y,
            air_temperature_measurement_time,
            water_temperature_measurement_time)) %>% 
  mutate(detection_type = "capture") %>% 
  unite(observer, c("observers", "other_observers"), sep=",", na.rm = T) %>% 
  rename(start_time = start_time.y,
         end_time = end_time.y,
         survey_time = survey_time.x)

mid_surv_ves <- raw_survey_info %>% 
  left_join(raw_survey_ves, by = c("site", "date")) %>% 
  select(!c(fulcrum_id.x,
            fulcrum_id.y,
            observer,
            observer_other,
            site_other,
            start_time.x,
            end_time.x,
            survey_time.y,
            air_temperature_measurement_time,
            water_temperature_measurement_time)) %>% 
  mutate(detection_type = "visual") %>% 
  unite(observer, c("observers", "other_observers"), sep=",", na.rm = T) %>% 
  rename(start_time = start_time.y,
         end_time = end_time.y,
         survey_time = survey_time.x)

(raw_survey_acoustic)

mid_surv_aural <- raw_survey_info%>% 
  select(!c(fulcrum_id,
            site_other,
            start_time,
            end_time,
            survey_time)) %>% 
  mutate(detection_type = "aural")

# all surveys across survey types
surv_info <- bind_rows(mid_surv_capture, mid_surv_ves, mid_surv_aural)

# unique surveys only... looks like this is not used?
# mid_unique_survey <- bind_rows(survey_acoustic, survey_capture, survey_ves) %>% 
#   select(!c(fulcrum_id, observer, observer_other, acoustic_survey_comments)) %>% 
#   full_join(surv_info, by = c("site", "date", "detection_type")) %>% 
#   select(!c(site_other, air_temperature_measurement_time, water_temperature_measurement_time, end_time.y,
#             start_time.y, observers, other_observers, survey_time.x, survey_time.y)) %>% 
#   rename(start_time = start_time.x,
#          end_time = end_time.x) %>% 
#   mutate(survey_time = "Night") %>% # confirm all surveys are night surveys...
#   unite(survey_comments, c("survey_comments.x", "survey_description.x", "survey_comments.y", "survey_description.y"),
#         sep = ",", na.rm=T)

unique_survey <- surv_info %>% 
  group_by(site, date, detection_type) %>% 
  mutate(start_time = as_hms(mean(start_time)), # clean times
         end_time = as_hms(mean(end_time))) %>% 
  select(!c("water_temperature_measurement_time", "air_temperature_measurement_time", "other_observers", "observers")) %>% 
  unite(survey_comments, c("survey_comments", "sampling_event_comments", "survey_description"), na.rm = T, sep = ",") %>% 
  rename(wind = wind_conditions,
         sky = sky_conditions,
         relative_humidity_percent = humidity,
         pressure_psi = pressure, # need to confirm units
         wind_speed_m_s = wind_speed_ms,
         air_temp_c = air_temperature_c,
         dissolved_o2_percent = dissolved_oxygen,
         tds_ppm = total_dissolved_solids, # need to confirm units
         water_temp_c = water_temperature_c,
         p_h = ph) %>% # clean column names
  mutate(survey_time = str_to_lower(survey_time),
         site = str_to_lower(str_replace_all(site, "-", "_")),
         site = str_replace_all(site, " ", "_"),
         survey_time = if_else(is.na(survey_time), "night", survey_time),
         temp_id = cur_group_id()) %>% 
  filter(!duplicated(temp_id)) %>% 
  select(!temp_id) %>% 
  ungroup()



```

### Pull visit pkey from unique table above

```{r}

surv_fkey <- unique_visits_fkey %>% 
  select(date, visit_id, site)

# duplicates passed from visit_id generation

```

### Join visit pkey into surv fkey

```{r}

unique_survey_fkey <- unique_survey %>% 
  full_join(surv_fkey, by = c("date", "site")) %>% 
  mutate(p_h = if_else(p_h == 0.00, NA, p_h)) %>% 
  group_by(site, date, detection_type) %>% 
  mutate(survey_id = UUIDgenerate(output = c("uuid"))) %>% # move to end, after antijoin wtih survey table
  filter(!duplicated(survey_id)) %>% # this should not be needed once above corrections made
  mutate(duration_min = if_else(end_time < start_time,
                            as_hms(86400) - start_time + end_time,
                            end_time - start_time),
         duration_min = duration_min/60,
         duration_min = str_remove(duration_min, " secs"),
         duration_min  = round(as.numeric(duration_min), 2)) %>%  # why rounding duration to 2? Put in data dictionary description
  group_by(date, site) %>% 
  mutate(survey_time = if_else(is.na(survey_time), "night", survey_time)) %>% 
  select(!c(conductivity_us))

```

### final survey table

```{r}

fin_survey <- unique_survey_fkey %>% 
  ungroup() %>% 
  select(!c(date, survey_time, site)) %>% 
  rename(duration_minutes = duration_min) %>% # define properly above and delete
  mutate(duration_minutes = as.integer(duration_minutes))# define properly above and delete

warningCondition("Survey append commented out. Rewrite as single transaction.")  
# dbAppendTable(connection, "survey", fin_survey) # don't drop fulcrum_id until here.

```

## Capture table

### merge and clean capture tables

```{r}
#cap_col <- read_csv(here("clean_tables", "capture.csv"))


mid_cap <- survey_info %>% 
  left_join(survey_capture, by = c("site" , "date")) %>% # could we do this on fin_survey or similar, to carry forward all names and ids? Need fulcrum_id though.
  select(fulcrum_id.y, detection_type, date, site, survey_time.x) %>% 
  rename(fulcrum_id = fulcrum_id.y,
         survey_time = survey_time.x) %>% 
  left_join(capture_obs, by = c("fulcrum_id" = "fulcrum_parent_id")) %>% # revisit later after cleaning above. Should not need left join, full join should return same and catch any errors if not
  select(detection_type.x, date, site, survey_time, detection_type.x, body_temperature, bag_id, species_capture, 
         time_of_capture, microhabitat_type, microhabitat_wet, microhabitat_temperature, amphibian_comments)

mid_samp_proc <- samp_proces %>% 
  left_join(samp_procces_obs, by= c("fulcrum_id" = "fulcrum_parent_id")) %>% # full join? to catch errors
  select(!c(fulcrum_id,
            fulcrum_id.y,
            fulcrum_record_id,
            c(norep_bathvolume_50ml_acid_05ml:ul_of_norep_01688mgml), # explicitly drop (or explicitly select), not robust to change in column order
            c(photo:photo_url),
            c(amp_ig_ne_injected:amp_ig_comments))) 

# separate sample negative controls
neg_controls <- mid_samp_proc %>% 
  filter(species_capture == "Negative Control") %>% 
  select(!c(processor_other,
            sex_other,
            survey_comments,
            life_stage_other,
            c(species_capture_other:body_mass))) %>%  # explicitly drop (or explicitly select), not robust to change in column order
  rename(site = location) %>% 
  mutate(species_capture = str_to_lower(str_replace_all(species_capture, " ", "_")),
         survey_time = str_to_lower(survey_time),
         site = str_to_lower(str_replace_all(site, " ", "_")))

# drop sample negative controls
mid_samp_proc <- mid_samp_proc %>% 
  filter(!species_capture == "Negative Control") %>% 
  select(!species_capture_other)

unique_cap <- mid_samp_proc %>% 
  left_join(mid_cap, by = c("location"= "site", "date", "bag_id")) %>% # any chance of a mid_cap with no samps, but relevant data? If so, full join? Or bind_rows.
  select(!c(survey_time.y, species_capture.y, life_stage_other, sex_other,
            survey_comments)) %>% 
  rename(detection_type = detection_type.x,
         survey_time = survey_time.x,
         species_capture = species_capture.x,
         site = location) %>% 
  unite(processor, c("processor", "processor_other"), na.rm = T, sep = "") %>% 
  mutate(site = str_to_lower(str_replace_all(site, "-", "_")),
         site = str_replace_all(site, " ", "_"),
         species_capture = str_to_lower(str_replace_all(species_capture, " ", "_")),
         survey_time = str_to_lower(survey_time)) %>% 
  unite(capture_comments, c("amphibian_comments", "capture_comments"), na.rm = T,
        sep = ", ") %>% 
  rename(body_temp_c = body_temperature,
         svl_mm = snout_vent_length,
         body_and_bag_mass_g = body_and_bag_mass,
         bag_mass_g = bag_mass,
         body_mass_g = body_mass) %>%
  mutate(amp_id = if_else(capture_mark_recapture %in% ("cf358e11-d6da-4637-af56-c384d683e6fb"), "Pe_AMP00000", amp_id)) # to what does this cmr id correspond?



```

### generate capture_id

```{r}

cap_fkey <- unique_survey_fkey %>%
  select(site, date, detection_type, survey_time, survey_id)


unique_cap_fkey <- unique_cap %>% 
  mutate(detection_type = "capture",
         capture_id = UUIDgenerate(n = n())) %>% 
  left_join(cap_fkey, by = c("site", "date", "detection_type", "survey_time"))
  

```

### final capture table

#### empty column search

## create empty columns in DB which are new to this data set

```{r}

final_cap <- unique_cap_fkey %>% 
  select(!c(survey_time, detection_type, site, date)) %>% 
  rename(microbiome_swab_id = microbiome_id,
         sierra_bd_swab_id = bd_swab_id_sv) %>% 
  mutate(sex = str_to_lower(sex),
         capture_type = str_to_lower(capture_type),
         life_stage = str_to_lower(life_stage)) %>% 
  mutate(across(c(bd_swab_id:genetic_id), ~ifelse(str_detect(., "00000"), NA, .))) %>% 
  select(!c(sierra_bd_swab_id, bacterial_swab_id_foundations, location_other))


q_col <- "SELECT *
          FROM capture
          LIMIT 1;"

col_names <- dbGetQuery(connection, q_col) %>%
  colnames()

db_cols <- final_cap %>%
  colnames()

missing_cols <- setdiff(db_cols, col_names) %>%
  print() %>%
  as.character()


add_col_q <- paste0("alter table capture
                  add ", missing_cols[1]," varchar;")

dbExecute(connection, add_col_q)

add_col_q <- paste0("alter table capture
                  add ", missing_cols[2]," varchar;")

dbExecute(connection, add_col_q)



dbAppendTable(connection, "capture", final_cap)

```

## VES

### clean and merged ves data

```{r}

ves_c <- read_csv(here("clean_tables", "ves.csv"))

mid_ves <- survey_ves %>% 
  left_join(ves_obs, by = c("fulcrum_id" = "fulcrum_parent_id")) %>% 
  select(!c(fulcrum_id, detection_type.x, fulcrum_id.y, fulcrum_record_id, start_time, end_time,
            survey_description)) %>% 
  rename(detection_type = detection_type.y)


unique_ves <- mid_ves %>% 
  unite(observer, c("observer", "observer_other"), na.rm = T, sep = "") %>% 
  unite(species_ves, c("species_ves", "species_ves_other"), na.rm = T, sep = "") %>% 
  mutate(site = str_to_lower(str_replace_all(site, " ", "_")),
         site = str_replace_all(site, "-", "_"),
         survey_time = str_to_lower(survey_time),
         species_ves = str_to_lower(str_replace_all(species_ves, " ", "_"))) %>% 
  rename(ves_comments = comments_ves,
         count = count_ves)


```

### populate VES fkey

```{r}

ves_fkey <- unique_survey_fkey %>% 
  select(site, date, detection_type, survey_time, survey_id)

unique_ves_fkey <- unique_ves %>% 
  left_join(ves_fkey, by = c("site", "date", "detection_type", "survey_time")) %>% 
  mutate(ves_id = UUIDgenerate(n = n()),
         species_ves = if_else(species_ves == "", NA, species_ves)) %>% 
  drop_na(species_ves)



```

### final ves table

```{r}

final_ves <- unique_ves_fkey %>% 
  select(!c(site, date, survey_time, detection_type))

dbAppendTable(connection, "ves", final_ves)

```

## aural

### clean and merge arual

```{r}

aural_cols <- read_csv(here("clean_tables", "aural.csv"))


mid_aural <- survey_acoustic %>% 
  left_join(acoustic_obs, by = c("fulcrum_id" = "fulcrum_parent_id"))%>% 
  select(!c(fulcrum_id, detection_type.x, fulcrum_id.y, fulcrum_record_id, start_time, end_time,
            observer_other, species_acoustic_other, acoustic_survey_comments))

unique_aural <- mid_aural %>% 
  rename(detection_type = detection_type.y) %>% 
  mutate(site = str_to_lower(str_replace_all(site, " ", "_")),
         site = str_replace_all(site, "-", "_"),
         species_acoustic = str_to_lower(str_replace_all(species_acoustic, " ", "_")),
         survey_time = str_to_lower(survey_time)) %>% 
  rename(species_aural = species_acoustic,
         aural_comments = acoustic_species_comments)
  


```

### populate aural fkey

```{r}

aural_fkey <- unique_survey_fkey %>% 
  select(site, date, detection_type, survey_time, survey_id)


unique_aural_fkey <- unique_aural %>% 
  mutate(detection_type = "aural",
         aural_id = UUIDgenerate(n = n())) %>% 
  left_join(aural_fkey, by = c("site", "date", "detection_type", "survey_time"))
  

```

### final aural table

```{r}

final_aural <- unique_aural_fkey %>% 
  select(!c(site, date, detection_type, survey_time))

dbAppendTable(connection, "aural", final_aural)

```

## CMR table

```{r}

cmr_cols <- read_csv(here("clean_tables", "penn_cmr.csv"))

final_cmr <- cmr %>% 
  select(!c(species_other, location, species)) %>% 
  unite(cmr, c("cmr_id", "cmr_id_other"), na.rm = T, sep = "") %>% 
  rename(capture_mark_recapture = fulcrum_id,
         cmr_id = cmr)

dbAppendTable(connection, "cmr", final_cmr)

```
