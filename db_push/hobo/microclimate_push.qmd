---
title: "sensor build"
format: html
editor: source
---

## Setup

```{r}
librarian::shelf(tidyverse, vroom, here, janitor, dataPreparation, lubridate, stringr, RPostgres, DBI, uuid, hms, RIBBiTR-BII/ribbitrrr, readxl, ggplot2, plotly, scales)
# librarian::shelf(RIBBiTR-BII/ribbitrrr, update_all = TRUE)

## Connect to DB
dbcon = hopToDB("wibbitr")

## Point to local data directory
ddir = Sys.getenv("data_dir")  # data directory
# Keeping .csv files in a central directory. Naming convention uses download date to distinguish batches.
wddir = here(ddir, "microclimate", "hobo_data_combined", '2026-02-04') # working data directory
```

# DB pointers
```{r}
db_site = tbl(dbcon, Id("survey_data", "site"))
db_region = tbl(dbcon, Id("survey_data", "region"))
db_country = tbl(dbcon, Id("survey_data", "country"))

db_logger = tbl(dbcon, Id("microclimate_data", "logger"))
db_sensor = tbl(dbcon, Id("microclimate_data", "sensor"))
db_ts_temp = tbl(dbcon, Id("microclimate_data", "ts_temperature"))
db_ts_ill = tbl(dbcon, Id("microclimate_data", "ts_illuminance"))
db_ts_rh = tbl(dbcon, Id("microclimate_data", "ts_relative_humidity"))
db_ts_dp = tbl(dbcon, Id("microclimate_data", "ts_dew_point"))
```

# import and manipulate each file for consistency
```{r}
# import deployment data
deployment_file = here(ddir, "microclimate", "hobo_logger_deployment", 'HOBO logger deployment data_2026-02-04.xlsx')
sheetnames = c("Pennsylvania",
               "Panama",
               "Brazil",
               "Sierra Nevada")
deployment = lapply(sheetnames, read_excel, path = deployment_file)  # eek, what to do with this!

# List all hob combined CSV files in the directory
csv_files = list.files(path = wddir, pattern = "*.csv", full.names = TRUE)

# importing function
files_to_tibble_list = function(file_list) {
  tibble_list = lapply(file_list, function(file) {
    # Read the CSV file with vroom
    print(basename(file))
    df = vroom(file, col_types = cols(
      DateTime = col_character(),
      Site = col_character(),
      .default = col_guess()
    )) %>%
      mutate(src = basename(file))
    # as_tibble(df)
  })
  
  return(tibble_list)
}

#import
ts_raw_ls = files_to_tibble_list(csv_files)

# check column names across files
raw_compare = compare_df_cols(ts_raw_ls)

# check date formats across files
raw_date_preview = lapply(ts_raw_ls, function(df) {
  df %>%
    slice_head(n = 48) %>%
    pull(DateTime)
})

# check time zones across files
raw_time_zones = lapply(ts_raw_ls, function(df) {
  df %>%
    select(TimeZone) %>%
    distinct() %>%
    pull(TimeZone)
})

# bring into one data frame
ts_raw = bind_rows(ts_raw_ls)

```

```{r}

# parse datetime
ts_joined = ts_raw %>%
  clean_names() %>%
  rename(date_time_raw = date_time) %>%
  filter(!is.na(date_time_raw)) %>%
  mutate(date_time_parsed = parse_date_time(date_time_raw, c("ymd HMS", "ymd", "mdy HM")))

# parse timezone
tzs = ts_joined %>%
  select(time_zone) %>%
  distinct() %>%
  mutate(tz_clean = case_match(time_zone,
                               "GMT-0:200" ~ "Etc/GMT+2",
                               "GMT-04:00" ~ "Etc/GMT+4",
                               c("GMT-05:00", "GMT-0:500") ~ "Etc/GMT+5",
                               c("GMT-07:00", "GMT-0:700", "PDT") ~ "Etc/GMT+7",
                               c("GMT-08:00", "GMT-8") ~ "Etc/GMT+8",
                               .default = NA
  ))

# convert to UTC
ts_clean_dates = ts_joined %>%
  left_join(tzs, by = "time_zone") %>%
  group_split(time_zone) %>%
  map_dfr(~ mutate(.x, date_time_local = force_tz(date_time_parsed, tzone = unique(.x$tz_clean)))) %>%
  mutate(timestamp_utc = with_tz(date_time_local, tzone = "UTC")) %>%
  select(-date_time_parsed,
         -tz_clean,
         -date_time_local)

# parse logger metadata
ts_clean = ts_clean_dates %>%
  rename(site_hobo = site,
         microhabitat = location,
         relative_humidity = rh,
         illuminance = intensity_lux,
         height_cm = height) %>%
  mutate(site_microclimate = case_match(site_hobo,
                           "Admin" ~ "admin_pond",
                           "Phelps" ~ "phelps_pond",
                           "RV" ~ "rv_pond",
                           "Tuttle" ~ "tuttle_pond",
                           "TW" ~ "tryon_weber",
                           "Vorisek" ~ "vorisek_pond",
                           "Wood" ~ "wood_lab_pond",
                           "AltosdePiedra" ~ "altos_de_piedra",
                           "Campestre" ~ "hotel_campestre",
                           "CerroNegro" ~ "cerro_negro",
                           "Rabbit" ~ "rabbit_stream",
                           "RioBlanco" ~ "rio_blanco",
                           "Tigrero" ~ "rio_tigrero",
                           "SouthForkEastRockCk" ~ "east_rock_creek_s",
                           "WestForkEastRockCk" ~ "east_rock_creek_w",
                           "BO01" ~ "t4",
                           "BO02" ~ "t6",
                           "BO03" ~ "t7",
                           "SV04" ~ "s1",
                           "SV05" ~ "s2",
                           .default = site_hobo),
         height_cm = as.numeric(str_remove(height_cm, "cm"))) %>%
  pivot_longer(c(temperature, relative_humidity, dew_point, illuminance),
               names_to = "sensor_type") %>%
  filter(!is.na(value),
         !(sensor_type == "relative_humidity" & value == 1)) %>%
  mutate(units = case_match(sensor_type,
                            "temperature" ~ "degrees_celsius_c",
                            "dew_point" ~ "degrees_celsius_c",
                            "illuminance" ~ "lux_lx",
                            "relative_humidity" ~ "percent_saturation")) %>%
  group_by(src) %>%
  mutate(src_start = min(timestamp_utc)) %>%
  ungroup()
  
# checks
colnames(ts_clean)

sites = ts_clean %>%
  select(site_microclimate) %>%
  distinct()

unique(ts_clean$microhabitat)
unique(ts_clean$height_cm)

```

## gel
```{r}
# create UUIDs & align with existing data
sensor_gelled = ts_clean %>%
  select(site_microclimate,
         microhabitat,
         height_cm,
         sensor_type,
         units) %>%
  distinct() %>%
  left_join(db_site %>%
              select(site, site_id) %>% collect(), by = c("site_microclimate" = "site")) %>%
  left_join(db_logger %>%
              select(logger_id, microhabitat, site_id, site_code_alt) %>%
              collect(), by = c("microhabitat", "site_id")) %>%
  left_join(db_sensor %>%
              select(sensor_id, sensor_type, height_cm, logger_id) %>%
              collect(), by = c("sensor_type", "height_cm", "logger_id")) %>%
  group_by(site_id, microhabitat) %>%
  mutate(logger_id = if_else(is.na(logger_id), UUIDfromName("680a4e4e-4135-432f-a8ef-a6acdc379efd", paste0(site_id, microhabitat)), logger_id)) %>%
  ungroup() %>%
  mutate(sensor_id = if_else(is.na(sensor_id), UUIDfromName("aeaf491b-ca51-461c-b6e3-bcc75ab35eeb", paste0(logger_id, sensor_type, height_cm)), sensor_id))

ts_gelled = ts_clean %>%
  left_join(sensor_gelled, by = c("site_microclimate", "microhabitat", "sensor_type", "height_cm")) %>%
  select(sensor_id,
         timestamp_utc,
         value,
         sensor_type,
         src,
         src_start)

# check all data have sensors
peace = ts_gelled %>%
  filter(is.na(sensor_id))

# check for timeseries overlap
dupes_pre = get_dupes(ts_gelled, sensor_id, sensor_type, timestamp_utc)

dupes_paired = dupes_pre %>%
  arrange(src_start) %>%
  group_by(sensor_id, sensor_type, timestamp_utc) %>%
  summarize(src_n = n(),
            src_f = first(src),
            src_start_f = first(src_start),
            src_l = last(src),
            src_start_l = last(src_start),
            .groups = "drop")

dupes_summary = dupes_paired %>%
  group_by(sensor_id,
           src_f,
           src_l) %>%
  summarize(n_values = n(),
            start_overlap_timestamp_utc = min(timestamp_utc),
            end_overlap_timestamp_utc = max(timestamp_utc),
            .groups = "drop") %>%
  mutate(overlap_duration_minutes = interval(start = start_overlap_timestamp_utc, end = end_overlap_timestamp_utc) %/% dminutes(1)) %>%
  left_join(sensor_gelled, by = "sensor_id") %>%
  arrange(src_f,
          start_overlap_timestamp_utc,
          site_microclimate) %>%
  rename(src_file_1 = src_f,
         src_file_2 = src_l) %>%
  select(-sensor_id,
         -site_id,
         -logger_id,
         -site_code_alt,
         -units)

# write.csv(dupes_summary, here("staging", paste0("microclimate_overlap_report_", today(), ".csv")))

pair_check = dupes_paired %>%
  filter(src_f == src_l) %>%
  rename(src = src_f) %>%
  select(sensor_id,
         timestamp_utc,
         src) %>%
  distinct()

# keep later duplicates, drop newer
drop_between_file_pairs_oldest = dupes_paired %>%
  select(sensor_id,
         sensor_type,
         timestamp_utc,
         src_f) %>%
  rename(src = src_f)

add_within_file_pairs_resolved = ts_gelled %>%
  inner_join(pair_check, by = c("sensor_id", "timestamp_utc", "src")) %>%
  arrange(sensor_id, timestamp_utc, src) %>%
  group_by(sensor_id, timestamp_utc) %>%
  slice_head(n = 1) %>%
  ungroup()

ts_distinct = ts_gelled %>%
  anti_join(drop_between_file_pairs_oldest, by = c("sensor_id", "sensor_type", "timestamp_utc", "src")) %>%
  bind_rows(add_within_file_pairs_resolved)

# # check for dupes
# dupes_pre = get_dupes(ts_gelled, sensor_id, timestamp_utc)
# 
# # drop dupes (could be more careful about this...)
# ts_distinct = ts_gelled %>%
#   group_by(sensor_id, timestamp_utc) %>%
#   slice_head(n = 1) %>%
#   ungroup()

dupes_post = get_dupes(ts_distinct, sensor_id, timestamp_utc)

# split into sensor types

# temp
temp_distinct = ts_distinct %>%
  filter(sensor_type == "temperature") %>%
  rename(temperature_c = value)

# rh
rh_distinct = ts_distinct %>%
  filter(sensor_type == "relative_humidity") %>%
  rename(relative_humidity_percent = value)

# dp
dp_distinct = ts_distinct %>%
  filter(sensor_type == "dew_point") %>%
  rename(dew_point_c = value)

# ill
ill_distinct = ts_distinct %>%
  filter(sensor_type == "illuminance") %>%
  rename(illuminance_lux = value)

```

## visual checks
```{r}
#| fig-width: 10
#| fig-height: 8

# plot illuminance with hour of day
site_lookup =  db_site %>%
  left_join(db_region, by = "region_id") %>%
  left_join(db_country, by = "country_id") %>%
  select(site_id,
         site,
         region,
         country,
         time_zone) %>%
  collect()
  
ill_vis = ill_distinct %>%
  left_join(sensor_gelled, by = "sensor_id") %>%
  left_join(site_lookup, by = "site_id") %>%
  mutate(time_utc = as_hms(timestamp_utc),
         year = year(timestamp_utc))

# brazil
ill_vis_br = ill_vis %>%
  filter(country == "brazil") %>%
  mutate(time_local = as_hms(with_tz(force_tz(timestamp_utc, tzone = "UTC"), tzone = "America/Sao_Paulo")))

p_ill_br = ggplot(ill_vis_br, aes(x = time_local, y = illuminance_lux, color = src)) +
  geom_point(alpha = 1) +
  facet_wrap("site_microclimate") +
  theme_minimal() +
  scale_y_log10() +
  labs(title = "Brazil Illuminance",
       x = "Local Time",
       y = "Illuminance (lux)") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_time(breaks = as_hms(c("04:00:00", "08:00:00", "12:00:00", "16:00:00", "20:00:00")),
                   labels = c("04:00", "08:00", "12:00", "16:00", "20:00"))

# panama
ill_vis_pa = ill_vis %>%
  filter(country == "panama") %>%
  mutate(time_local = as_hms(with_tz(force_tz(timestamp_utc, tzone = "UTC"), tzone = "America/Panama")))

p_ill_pa = ggplot(ill_vis_pa, aes(x = time_local, y = illuminance_lux, color = src)) +
  geom_point(alpha = 0.1) +
  facet_wrap("site_microclimate") +
  theme_minimal() +
  scale_y_log10() +
  labs(title = "Panama Illuminance",
       x = "Local Time",
       y = "Illuminance (lux)") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_time(breaks = as_hms(c("04:00:00", "08:00:00", "12:00:00", "16:00:00", "20:00:00")),
                   labels = c("04:00", "08:00", "12:00", "16:00", "20:00"))

# california
ill_vis_ca = ill_vis %>%
  filter(region == "california") %>%
  mutate(time_local = as_hms(with_tz(force_tz(timestamp_utc, tzone = "UTC"), tzone = "America/Los_Angeles")))

p_ill_ca = ggplot(ill_vis_ca, aes(x = time_local, y = illuminance_lux, color = src)) +
  geom_point(alpha = 0.1) +
  facet_wrap("site_microclimate") +
  theme_minimal() +
  scale_y_log10() +
  labs(title = "California Illuminance",
       x = "Local Time",
       y = "Illuminance (lux)") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_time(breaks = as_hms(c("04:00:00", "08:00:00", "12:00:00", "16:00:00", "20:00:00")),
                   labels = c("04:00", "08:00", "12:00", "16:00", "20:00"))

# pennsylvania
ill_vis_pe = ill_vis %>%
  filter(region == "pennsylvania") %>%
  mutate(time_local = as_hms(with_tz(force_tz(timestamp_utc, tzone = "UTC"), tzone = "America/New_York")))

p_ill_pe = ggplot(ill_vis_pe, aes(x = time_local, y = illuminance_lux, color = src)) +
  geom_point(alpha = 0.1) +
  facet_wrap("site_microclimate") +
  theme_minimal() +
  scale_y_log10() +
  labs(title = "Pennsylvania Illuminance",
       x = "Local Time",
       y = "Illuminance (lux)") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_time(breaks = as_hms(c("04:00:00", "08:00:00", "12:00:00", "16:00:00", "20:00:00")),
                   labels = c("04:00", "08:00", "12:00", "16:00", "20:00"))

# ggplotly(p_ill_br)
# ggplotly(p_ill_pa)
# ggplotly(p_ill_ca)
# ggplotly(p_ill_pe)

ggsave(here("staging", "microclimate", "illuminance_local_time_brazil.png"), p_ill_br)
ggsave(here("staging", "microclimate", "illuminance_local_time_panama.png"), p_ill_pa)
ggsave(here("staging", "microclimate", "illuminance_local_time_california.png"), p_ill_ca)
ggsave(here("staging", "microclimate", "illuminance_local_time_pennsylvania.png"), p_ill_pe)

p_ill_br
p_ill_pa
p_ill_ca
p_ill_pe

```

## subset
```{r}
# loggers
subset_logger = sensor_gelled %>%
  select(all_of(colnames(db_logger))) %>%
  distinct()

tray = compare_for_staging(db_logger %>% collect(), subset_logger, "logger_id", report = "logger")
upsert_logger = bind_rows(tray$update,
                          tray$insert)

# sensors
subset_sensor = sensor_gelled %>%
  select(all_of(colnames(db_sensor))) %>%
  distinct()

tray = compare_for_staging(db_sensor %>% collect(), subset_sensor, "sensor_id", report = "sensor")
upsert_sensor = bind_rows(tray$update,
                          tray$insert)

# temperature
subset_temp = temp_distinct %>%
  select(all_of(colnames(db_ts_temp))) %>%
  distinct()

tray = compare_for_staging(db_ts_temp %>% collect(), subset_temp, c("sensor_id", "timestamp_utc"), report = "ts_temp")
peace = compare_updates(tray)
upsert_ts_temp = bind_rows(tray$update,
                          tray$insert)
drop_ts_temp = tray$orphan

# illuminance
subset_ill = ill_distinct %>%
  select(all_of(colnames(db_ts_temp))) %>%
  distinct()

tray = compare_for_staging(db_ts_ill %>% collect(), subset_ill, c("sensor_id", "timestamp_utc"), report = "ts_ill")
peace = compare_updates(tray)
upsert_ts_ill = bind_rows(tray$update,
                          tray$insert)
drop_ts_ill = tray$orphan

# relative humidity
subset_rh = rh_distinct %>%
  select(all_of(colnames(db_ts_temp))) %>%
  distinct()

tray = compare_for_staging(db_ts_rh %>% collect(), subset_rh, c("sensor_id", "timestamp_utc"), report = "ts_rh")
peace = compare_updates(tray)
upsert_ts_rh = bind_rows(tray$update,
                         tray$insert)
drop_ts_rh = tray$orphan

# dew point
subset_dp = dp_distinct %>%
  select(all_of(colnames(db_ts_temp))) %>%
  distinct()

tray = compare_for_staging(db_ts_dp %>% collect(), suset_dp, c("sensor_id", "timestamp_utc"), report = "ts_dp")
peace = compare_updates(tray)
upsert_ts_dp = bind_rows(tray$update,
                         tray$insert)
drop_ts_dp = tray$orphan

```

## write tables
```{r}

# update all landscape
dbBegin(dbcon)

tryCatch(
  {
    
    db_rows_upsert(dbcon, db_logger, upsert_logger, by="logger_id")
    # temp_logger = stage_to_temp(dbcon, db_logger, upsert_logger)
    # pointer = tbl(dbcon, temp_logger)
    # rows_upsert(db_logger, pointer, by="logger_id", in_place=TRUE)
    
    db_rows_upsert(dbcon, db_sensor, upsert_sensor, by="sensor_id")
    # temp_sensor = stage_to_temp(dbcon, db_sensor, upsert_sensor)
    # pointer = tbl(dbcon, temp_sensor)
    # rows_upsert(db_sensor, pointer, by="sensor_id", in_place=TRUE)
    
    db_rows_upsert(dbcon, db_ts_dp, upsert_ts_dp, c("sensor_id", "timestamp_utc"))
    # temp_ts_dp = stage_to_temp(dbcon, db_ts_dp, upsert_ts_dp)
    # pointer = tbl(dbcon, temp_ts_dp)
    # rows_upsert(db_ts_dp, pointer, by=c("sensor_id", "timestamp_utc"), in_place=TRUE)
    db_rows_delete(dbcon, db_ts_dp, drop_ts_dp, c("sensor_id", "timestamp_utc"))
    
    db_rows_upsert(dbcon, db_ts_ill, upsert_ts_ill, c("sensor_id", "timestamp_utc"))
    # temp_ts_ill = stage_to_temp(dbcon, db_ts_ill, upsert_ts_ill)
    # pointer = tbl(dbcon, temp_ts_ill)
    # rows_upsert(db_ts_ill, pointer, by=c("sensor_id", "timestamp_utc"), in_place=TRUE)
    db_rows_delete(dbcon, db_ts_ill, drop_ts_ill, c("sensor_id", "timestamp_utc"))
    
    db_rows_upsert(dbcon, db_ts_rh, upsert_ts_rh, c("sensor_id", "timestamp_utc"))
    # temp_ts_rh = stage_to_temp(dbcon, db_ts_rh, upsert_ts_rh)
    # pointer = tbl(dbcon, temp_ts_rh)
    # rows_upsert(db_ts_rh, pointer, by=c("sensor_id", "timestamp_utc"), in_place=TRUE)
    db_rows_delete(dbcon, db_ts_rh, drop_ts_rh, c("sensor_id", "timestamp_utc"))
    
    db_rows_upsert(dbcon, db_ts_temp, upsert_ts_temp, c("sensor_id", "timestamp_utc"))
    # temp_ts_temp = stage_to_temp(dbcon, db_ts_temp, upsert_ts_temp)
    # pointer = tbl(dbcon, temp_ts_temp)
    # rows_upsert(db_ts_temp, pointer, by=c("sensor_id", "timestamp_utc"), in_place=TRUE)
    db_rows_delete(dbcon, db_ts_temp, drop_ts_temp, c("sensor_id", "timestamp_utc"))
    
    # Commit the transaction if successful
    dbCommit(dbcon)
    print("Transaction successful!")
    
  }, error = function(e) {
    # Rollback in case of error
    dbRollback(dbcon)
    message("Transaction failed: ", e$message)
  })

```


# import and bind all data into one big dataframe
```{r}
# List all CSV files in the directory
csv_files <- list.files(path = wddir, pattern = "*.csv", full.names = TRUE)

# Function to convert GMT offset to Etc/GMT format
convert_gmt_to_etc <- function(gmt_string) {
  # Extract the sign and the hours and minutes
  pattern <- "GMT([+-])(\\d{2}):(\\d{2})"
  matches <- regmatches(gmt_string, regexec(pattern, gmt_string))
  
  if (length(matches) == 0) {
    stop("Invalid GMT format")
  }
  
  sign <- matches[[1]][2]     # "+" or "-"
  hours <- as.integer(matches[[1]][3]) # Extract hours
  # minutes <- as.integer(matches[[1]][4]) # Extract minutes (not used)

  # Create the new Etc/GMT format
  etc_timezone <- paste0("Etc/GMT", sign, hours)
  
  return(etc_timezone)
}

# Initialize an empty list to store data frames
data_list <- list()

# Read each CSV file into a separate data frame and manipulate as needed
data_list <- lapply(csv_files, function(file) {
  # Read the CSV file
  data <- read_csv(file) %>%
    clean_names()

  return(data) # Return the manipulated data frame
})

data_list[[1]] = data_list[[1]] %>%
  mutate(time_zone = "GMT-02:00")

data_list[[7]] = data_list[[7]] %>%
  mutate(time_zone = "GMT-05:00")

data_list[[9]] = data_list[[9]] %>%
  mutate(time_zone = "GMT-07:00")

data_list[[10]] = data_list[[10]] %>%
  mutate(time_zone = "GMT-08:00")

# Read each CSV file into a separate data frame and manipulate as needed
data_list <- lapply(data_list, function(df) {

  # data = df %>%
  #   mutate(time_zone = map_chr(time_zone, ~ convert_gmt_to_etc(.x)))
  
  data = df %>%
    mutate(time_zone = convert_gmt_to_etc(time_zone),
           date_time = mdy_hm(date_time),
           timestamptz = with_tz(date_time, tz = time_zone))
    

  return(data) # Return the manipulated data frame
})

```

## convert timezones

```{r}

# Example usage
gmt_string <- "GMT-04:00"
gmt_string <- "GMT+02:00"
etc_timezone <- convert_gmt_to_etc(gmt_string)
print(etc_timezone)  # Output: "Etc/GMT-4"
```