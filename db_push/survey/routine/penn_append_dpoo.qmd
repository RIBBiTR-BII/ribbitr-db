---
title: "penn_append"
format: html
editor: source
---
# Setup

## Load Packages

```{r}
librarian::shelf(tidyverse, dbplyr, here, janitor, lubridate, RPostgres, stringr, DBI, parsedate, uuid, hms, RIBBiTR-BII/ribbitrrr)
# librarian::shelf(RIBBiTR-BII/ribbitrrr, update_all = TRUE)
```

## DB Connection

```{r}
## Connect to DB
dbcon <- hopToDB()

## Pull metadata from database
mdc = tbl(dbcon, Id("public", "all_columns")) %>%
  filter(table_schema == "survey_data") %>%
  collect()

## Point to local data directory
ddir = Sys.getenv("data_dir")  # data directory
# Keeping .csv files in a central directory. Naming convention uses download date to distinguish batches.
wddir = here(ddir, "fulcrum", 'penn', '2024-09-13') # working data directory

```


# 0 - Data Plan

## Goals

- Integrate batches of Penn survey data with other RIBBiTR data (including other Penn data) for combined analysis
- Compare with existing data to avoid duplicating, and facilitate automated updating
- Quality control for red flag data (potential or known issues)
- Upload to Database in transaction
- log transaction

## Data chains (someday we can automate this...)

- capture / survey / visit / site / region / location
- aural / survey / visit / site / region / location
- ves / survey / visit / site / region / location

# 1 - Import data


## Pull dependent tables for each data chain

### use naming convention "db\_" to distinguish the source

```{r}
# pull relevant chain tables from DB
db_aural = tbl(dbcon, Id("survey_data", "aural"))
db_capture = tbl(dbcon, Id("survey_data", "capture"))
db_ves = tbl(dbcon, Id("survey_data", "ves"))
db_survey = tbl(dbcon, Id("survey_data", "survey"))
db_visit = tbl(dbcon, Id("survey_data", "visit"))
db_site = tbl(dbcon, Id("survey_data", "site"))
db_region = tbl(dbcon, Id("survey_data", "region"))
db_country = tbl(dbcon, Id("survey_data", "country"))

```


## Load most recent raw CSV Exports
- use naming convention "raw_" to distinguish source
- name related tables similarly for natural grouping

```{r}
# general survey table
raw_survey_info <- read_csv(here(wddir, "1_penn_surveyinformation", "1_penn_surveyinformation.csv"))

# aural tables
raw_aural_survey <- read_csv(here(wddir, "2_penn_acousticsurvey", "2_penn_acousticsurvey.csv"))
raw_aural_obs <- read_csv(here(wddir, "2_penn_acousticsurvey", "2_penn_acousticsurvey_acoustic_survey.csv"))

# ves tables
raw_ves_survey <- read_csv(here(wddir, "4_penn_visualencountersurvey", "4_penn_visualencountersurvey.csv"))
raw_ves_obs <- read_csv(here(wddir, "4_penn_visualencountersurvey", "4_penn_visualencountersurvey_visual_encounter_information.csv"))

# capture tables
raw_capture_survey <- read_csv(here(wddir, "5_penn_capturesurvey", "5_penn_capturesurvey.csv"))
raw_capture_obs <- read_csv(here(wddir, "5_penn_capturesurvey", "5_penn_capturesurvey_captured_amphibian_information.csv"))
raw_cmr <- read_csv(here(wddir, "supp_penn_cmrids", "supp_penn_cmrids.csv"))

# sample processing & obs tables
raw_sample_processing <- read_csv(here(wddir, "6_penn_sampleprocessing", "6_penn_sampleprocessing.csv"))
raw_sample_obs <- read_csv(here(wddir, "6_penn_sampleprocessing", "6_penn_sampleprocessing_amphibian_capture_survey_collections.csv"))
```
# 2 - Clean data

## check for null columns & duplicated rows
- purely informational, all action taken in next step

```{r}

null_columns = function(dataframe) {
  filtered = dataframe %>%
    select(where(~ all(is.na(.)))) %>%
    colnames()
}

# check null columns
(null_columns(raw_survey_info))
(null_columns(raw_aural_survey))
(null_columns(raw_aural_obs))
(null_columns(raw_ves_survey))
(null_columns(raw_ves_obs))
(null_columns(raw_capture_survey))
(null_columns(raw_capture_obs))
(null_columns(raw_cmr))
(null_columns(raw_sample_processing))
(null_columns(raw_sample_obs))

# check duplicated rows
any(duplicated(raw_survey_info))
any(duplicated(raw_aural_survey))
any(duplicated(raw_aural_obs))
any(duplicated(raw_ves_survey))
any(duplicated(raw_ves_obs))
any(duplicated(raw_capture_survey))
any(duplicated(raw_capture_obs))
any(duplicated(raw_cmr))
any(duplicated(raw_sample_processing))
any(duplicated(raw_sample_obs))

```

## Drop irrelevant & fix structural issues
- clean column names
- rename/mutate/drop specific columns
- Split, concatenate, coalesce related columns
- Convert to accurate data types/units/naming conventions
- drop unnecessary rows
- NA formatting

```{r}

# Fulcrum columns to drop. Best practice to drop by name
to_drop = c(
  "created_at",
  "updated_at",
  "created_by",
  "updated_by",
  "system_created_at",
  "system_updated_at",
  "version",
  "status",
  "project",
  "assigned_to",
  "latitude", # could this be useful?
  "longitude", # could this be useful?
  "geometry",
  "fulcrum_record_id",
  "site_other" # ignoring sites outside RIBBiTR... could include though.
)

calc_duration = function(start_time, end_time) {
  duration = if_else(end_time < start_time,
                         as_hms(86400) - start_time + end_time,
                         end_time - start_time)
  duration = duration / 60
  duration = str_remove(duration, " secs")
  duration = as.integer(round(as.numeric(duration), 0))
}

# Begin cleaning

clean_survey_info <- raw_survey_info %>%
  clean_names() %>% 
  rename(air_temp_c = air_temperature_c,
         air_time = air_temperature_measurement_time,
         water_temp_c = water_temperature_c,
         water_time = water_temperature_measurement_time,
         wind = wind_conditions,
         wind_speed_m_s = wind_speed_ms,
         sky = sky_conditions,
         relative_humidity_percent = humidity,
         pressure_psi = pressure,
         dissolved_o2_percent = dissolved_oxygen,
         tds_ppm = total_dissolved_solids,
         p_h = ph,
         comments_visit = sampling_event_comments,
         survey_info_id = fulcrum_id) %>%
  unite(observers_survey, c("observers", "other_observers"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         comments_visit = str_replace_all(comments_visit, "\\n", ". "),
         pressure_psi = ifelse(pressure_psi == 0, NA, pressure_psi),
         number_observers = as.integer(str_count(observers_survey, ",") + 1)) %>%
  select(-any_of(to_drop),
         -start_time,
         -end_time,
         -survey_time) %>%
  filter(!if_all(everything(), is.na))  # drop any rows all null

clean_aural_survey <- raw_aural_survey %>%
  clean_names() %>% 
  rename(comments_survey = acoustic_survey_comments) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         comments_survey = str_replace_all(comments_survey, "\\n", ". "),
         duration_minutes = calc_duration(start_time, end_time),
         detection_type = "aural",
         created_at = with_tz(ymd_hms(created_at, tz = "UTC"), "America/New_York"),
         survey_date = as.Date(ifelse(hour(created_at) > 12, date(created_at), date(created_at) - days(1)), origin = "1970-01-01"),
         date = as.Date(ifelse(survey_date - date > 1, date, survey_date), origin = "1970-01-01")) %>%
  unite(observer_aural, c("observer", "observer_other"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(-any_of(to_drop),
         -survey_date,
         -survey_time,) %>%
  filter(!if_all(everything(), is.na),
         !is.na(site))  # drop any rows all null

clean_aural_obs <- raw_aural_obs %>%
  clean_names() %>%
  rename(species_aural = species_acoustic,
         species_aural_other = species_acoustic_other,
         comments_aural = acoustic_species_comments) %>%
  mutate(aural_id = fulcrum_id,
         species_aural = coalesce(species_aural, species_aural_other),
         species_aural = str_to_lower(str_replace_all(species_aural, " ", "_")),
         comments_aural = str_replace_all(comments_aural, "\\n", ". ")) %>%
  select(-any_of(to_drop),
         -species_aural_other) %>%
  filter(!if_all(everything(), is.na)) # drop any rows all null

clean_ves_survey <- raw_ves_survey %>%
  clean_names() %>% 
  rename(comments_survey = survey_description) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         comments_survey = str_replace_all(comments_survey, "\\n", ". "),
         duration_minutes = calc_duration(start_time, end_time),
         detection_type = "visual",
         created_at = with_tz(ymd_hms(created_at, tz = "UTC"), "America/New_York"),
         survey_date = as.Date(ifelse(hour(created_at) > 12, date(created_at), date(created_at) - days(1)), origin = "1970-01-01"),
         date = as.Date(ifelse(survey_date - date > 1, date, survey_date), origin = "1970-01-01")) %>%
  unite(observer_ves, c("observer", "observer_other"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(-any_of(to_drop),
         -survey_date,
         -survey_time) %>%
  filter(!if_all(everything(), is.na),
         !is.na(site))  # drop any rows all null

clean_ves_obs <- raw_ves_obs %>%
  clean_names() %>%
  mutate(ves_id = fulcrum_id,
         species_ves = coalesce(species_ves, species_ves_other),
         species_ves = str_to_lower(str_replace_all(species_ves, " ", "_")),
         comments_ves = str_replace_all(comments_ves, "\\n", ". ")) %>%
  select(-any_of(to_drop),
         -species_ves_other) %>%
  filter(!if_all(everything(), is.na))  # drop any rows all null

clean_capture_survey <- raw_capture_survey %>%
  clean_names() %>% 
  rename(comments_survey = survey_comments) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         comments_survey = str_replace_all(comments_survey, "\\n", ". "),
         duration_minutes = calc_duration(start_time, end_time),
         detection_type = "capture",
         created_at = with_tz(ymd_hms(created_at, tz = "UTC"), "America/New_York"),
         survey_date = as.Date(ifelse(hour(created_at) > 12, date(created_at), date(created_at) - days(1)), origin = "1970-01-01"),
         date = as.Date(ifelse(survey_date - date > 1, date, survey_date), origin = "1970-01-01")) %>%
  unite(observer_capture, c("observer", "observer_other"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(-any_of(to_drop),
         -survey_date,
         -survey_time) %>%
  filter(!if_all(everything(), is.na),
         !is.na(site))  # drop any rows all null

clean_capture_obs <- raw_capture_obs %>%
  clean_names() %>%
  rename(body_temp_c = body_temperature,
         comments_capture = amphibian_comments,
         capture_latitude = latitude,
         capture_longitude = longitude,
         photo_id = bag_photo) %>%
  mutate(capture_id = fulcrum_id,
         species_capture = coalesce(species_capture, species_capture_other),
         species_capture = str_to_lower(str_replace_all(species_capture, " ", "_")),
         comments_capture = str_replace_all(comments_capture, "\\n", ". "),
         bag_id = ifelse(bag_id == "BAG00", NA, bag_id),
         photo = !is.na(photo_id)) %>%
  select(-any_of(to_drop),
         -all_of(c("capture_status",
                   "species_capture_other",
                   "bag_photo_caption",
                   "bag_photo_url"))) %>% # capture status: was this individual successfully captured?
  filter(!if_all(everything(), is.na))  # drop any rows all null 

clean_cmr <- raw_cmr %>%
  clean_names() %>%
  rename(site = location) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_")) %>%
  select(-any_of(to_drop)) %>%
  filter(!if_all(everything(), is.na))  # drop any rows all null

clean_sample_processing <- raw_sample_processing %>%
  clean_names() %>%
  rename(site = location,
         comments_sample = survey_comments) %>%
  mutate(site = str_to_lower(site),
         site = str_replace_all(site, "-", "_"),
         site = str_replace_all(site, " ", "_"),
         created_at = with_tz(ymd_hms(created_at, tz = "UTC"), "America/New_York"),
         survey_date = as.Date(ifelse(hour(created_at) > 12, date(created_at), date(created_at) - days(1)), origin = "1970-01-01"),
         date = as.Date(ifelse(survey_date - date > 1, date, survey_date), origin = "1970-01-01")) %>%
  unite(processor, c("processor", "processor_other"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(-any_of(to_drop),
         -survey_date,
         -location_other,
         -survey_time) %>%
  filter(!if_all(everything(), is.na)) # drop any rows all null

clean_sample_obs <- raw_sample_obs %>%
  clean_names() %>%
  rename(svl_mm = snout_vent_length,
         body_and_bag_mass_g = body_and_bag_mass,
         bag_mass_g = bag_mass,
         body_mass_g = body_mass,
         microbiome_swab_id = microbiome_id,
         comments_sample = capture_comments) %>%
  mutate(sex = str_to_lower(sex),
         sex_other = str_to_lower(sex_other),
         capture_type = str_to_lower(capture_type),
         life_stage = str_to_lower(life_stage),
         life_stage_other = str_to_lower(life_stage_other),
         species_capture = coalesce(species_capture, species_capture_other),
         species_capture = str_to_lower(str_replace_all(species_capture, " ", "_")),
         comments_sample = str_replace_all(comments_sample, "\\n", ". "),
         sample_id = fulcrum_id) %>%
  select(-any_of(to_drop),
         -fulcrum_record_id,
         -species_capture_other,
         -all_of(c("norep_bathvolume_50ml_acid_05ml",
                   "norep_bathvolume_100ml_acid_1ml",
                   "norep_bathvolume_200ml_acid_2ml",
                   "ul_of_norep_27mgml",
                   "ul_of_norep_135mgml",
                   "ul_of_norep_0675mgml",
                   "ul_of_norep_03375mgml",
                   "ul_of_norep_01688mgml",
                   "photo",
                   "photo_caption",
                   "photo_url",
                   "amp_ig_ne_injected",
                   "amp_ig_soak_volume",
                   "amp_ig_acidified",
                   "amp_ig_comments",
                   "bacterial_swab_id_foundations",
                   "bd_swab_id_foundations",
                   "microbiome_id_foundations",
                   "life_stage_other",
                   "sex_other"))) %>%
  filter(!if_all(everything(), is.na),
         !(species_capture == "negative_control"))


## Revisions: Handle special cases on a row-by-row basis
# (make repeatable & unique to observation, in case this exact observation(s) shows up again in a future data import)

# aquatic probe died, group returned later to measure. Comining two survey rows into one
row_a = clean_survey_info %>%
  filter(survey_info_id == "eea59aa0-4bae-4a1b-afa9-59c7285fbfe9")
row_b = clean_survey_info %>%
  filter(survey_info_id == "bbe6bef2-2ca6-43f3-b5e4-5db90f3ef82f")

revision_survey_info = row_a %>%
  mutate(observers_survey = paste0(row_a$observers_survey, ",", row_b$observers_survey),
         water_time = row_b$water_time,
         water_temp_c = row_b$water_temp_c,
         tds_ppm = row_b$tds_ppm,
         p_h = row_b$p_h)

clean_survey_info = clean_survey_info %>%
  filter(!survey_info_id %in% c("eea59aa0-4bae-4a1b-afa9-59c7285fbfe9",
                            "bbe6bef2-2ca6-43f3-b5e4-5db90f3ef82f")) %>%
  bind_rows(revision_survey_info)

clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "9f72d0b0-9252-46e6-8391-8531174e1f97"] = "BAG68"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "10e912f6-fdfb-4199-b7b0-aa137df728e4"] = "BAG70"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "42c0d6a7-cd2b-442e-9fe7-d7e37363de14"] = "BAG32"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "5a31383d-6210-42c7-8158-0f4818f0a66a"] = "BAG24"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "c844de38-b38f-43d8-a2db-6d4373ffb275"] = "BAG34"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "46c33c92-feb9-47ca-91d9-b519db773d69"] = "BAG64"
clean_sample_obs$bag_id[clean_sample_obs$fulcrum_id == "6d285d19-c288-456c-8dda-42ea35352dff"] = "BAG83"


clean_capture_obs$bag_id[clean_capture_obs$fulcrum_id == "78e8394d-60e4-4977-9f3b-9e57601b0980"] = "BAG10"
clean_capture_obs$bag_id[clean_capture_obs$fulcrum_id == "c513fba1-d5bb-41cb-add0-5330250c6d0f"] = "BAG06"
clean_capture_obs$bag_id[clean_capture_obs$fulcrum_id == "fb9736d2-d107-42a8-b5a0-09977b405010"] = "BAG18"
clean_capture_obs$bag_id[clean_capture_obs$fulcrum_id == "862a7efb-be07-40f8-ba1f-d0f4f90a8cd8"] = "BAG15"
clean_capture_obs$bag_id[clean_capture_obs$fulcrum_id == "4d5d73e8-847f-43e8-a8f1-db8c87371946"] = "BAG01"



```

# 3 Checks
```{r}
# check duplicates on visit nkey (ignoring time_of_day)
clean_survey_info %>%
  get_dupes(site, date)

```

## Generate stats for log
```{r}
dblog = list()
dblog$date_min = min(c(clean_survey_info$date,
      clean_aural_survey$date,
      clean_ves_survey$date,
      clean_capture_survey$date))

dblog$date_max = max(c(clean_survey_info$date,
      clean_aural_survey$date,
      clean_ves_survey$date,
      clean_capture_survey$date))
```

## Purge dates after date_min, to clean (1x only!)
```{r}
# chain_aural = tbl_chain("aural", mdc, until="region")
# chain_ves = tbl_chain("ves", mdc, until="region")
# chain_capture = tbl_chain("capture", mdc, until="region")
# 
# to_drop = rbind(tbl_join(dbcon, chain_aural) %>%
#                   filter(region == "pennsylvania",
#                          date >= dblog$date_min) %>%
#                   select(survey_id,
#                          visit_id) %>%
#                   collect(),
#                 tbl_join(dbcon, chain_capture) %>%
#                   filter(region == "pennsylvania",
#                          date >= dblog$date_min) %>%
#                   select(survey_id,
#                          visit_id) %>%
#                   collect(),
#                 tbl_join(dbcon, chain_ves) %>%
#                   filter(region == "pennsylvania",
#                          date >= dblog$date_min) %>%
#                   select(survey_id,
#                          visit_id) %>%
#                   collect())
# 
# to_drop_survey_id = unique(to_drop$survey_id)
# to_drop_visit_id = unique(to_drop$visit_id)
# 
# 
# db_aural_filter = db_aural %>%
#         filter(!(survey_id %in% to_drop_survey_id)) %>%
#   collect()
# db_capture_filter = db_capture %>%
#         filter(!(survey_id %in% to_drop_survey_id)) %>%
#   collect()
# db_ves_filter = db_ves %>%
#         filter(!(survey_id %in% to_drop_survey_id)) %>%
#   collect()
# db_survey_filter = db_survey %>%
#         filter(!(survey_id %in% to_drop_survey_id)) %>%
#   collect()
# db_visit_filter = db_visit %>%
#         filter(!(visit_id %in% to_drop_visit_id)) %>%
#   collect()
# 
# 
# # here we drop from
# dbBegin(dbcon)
#   
# tryCatch(
#   {
#     
#     dbWriteTable(dbcon, "aural", db_aural_filter, overwrite = TRUE)
#     dbWriteTable(dbcon, "capture", db_capture_filter, overwrite = TRUE)
#     dbWriteTable(dbcon, "ves", db_ves_filter, overwrite = TRUE)
#     dbWriteTable(dbcon, "survey", db_survey_filter, overwrite = TRUE)
#     dbWriteTable(dbcon, "visit", db_visit_filter, overwrite = TRUE)
#     
#     # Commit the transaction if successful
#     dbCommit(dbcon)
#     print("Transaction successful!")
# 
#   }, error = function(e) {
#     # Rollback in case of error
#     dbRollback(dbcon)
#     message("Transaction failed: ", e$message)
#   })

```


# One chain at a time

## Aural chain
- aural / survey / visit / site / region / location

### 3 - Unify aural data

```{r}
unified_aural = clean_aural_obs %>%
  full_join(clean_aural_survey, by = c("fulcrum_parent_id" = "fulcrum_id")) %>%
  select(-fulcrum_parent_id) %>%
  left_join(clean_survey_info, by = c("site", "date")) %>%
  left_join(db_site %>%
              select(tbl_keys("site", mdc)) %>%
              collect(),
            by = tbl_nkey("site", mdc)) %>%
  left_join(db_visit %>%
              select(tbl_keys("visit", mdc)) %>%
              collect(),
            by = tbl_nkey("visit", mdc)) %>%
  left_join(db_survey %>%
              select(tbl_keys("survey", mdc)) %>%
              filter(!is.na(visit_id)) %>%
              collect(),
            by = tbl_nkey("survey", mdc)) %>%
  filter(!is.na(site),
         !is.na(date))

if (any(is.na(unified_aural$site_id))) {
  stop("unknown aural sites found. More rigorous coding needed :)")
}

unified_aural %>%
  select(site, date, time_of_day, detection_type, start_time, end_time, comments_survey) %>%
  distinct() %>%
  get_dupes(site, date, time_of_day, detection_type)

```

### 4 - Gelled aural data

```{r}
gelled_aural = unified_aural %>%
  select(-comments_visit) %>% # update at end
  group_by_at(tbl_nkey("visit", mdc)) %>%
  mutate(visit_id = ifelse(is.na(visit_id), UUIDgenerate(), visit_id)) %>%
  ungroup() %>%
  group_by_at(tbl_nkey("survey", mdc)) %>%
  mutate(start_time = mean(start_time),
         end_time = mean(end_time),
         comments_survey = str_c(comments_survey, collapse = ", "),
         time_of_day = ifelse(start_time/(3600) > 6 & start_time/(3600) <= 18, "day", "night"),
         survey_id = ifelse(is.na(survey_id), first(fulcrum_id), survey_id),
         survey_id = ifelse(is.na(survey_id), UUIDgenerate(), survey_id)) %>%
  ungroup() %>%
  select(-fulcrum_id)

gelled_aural %>%
  select(site, date, time_of_day, detection_type, start_time, end_time, comments_survey) %>%
  distinct() %>%
  get_dupes(site, date, time_of_day, detection_type)

```

### 5 - Subset aural tables

```{r}

# visit
subset_aural_visit = gelled_aural %>%
  select(any_of(colnames(db_visit))) %>%
  distinct() %>%
  drop_na(visit_id)
tray = compare_for_staging(db_visit %>% collect(), subset_aural_visit, tbl_pkey('visit', mdc), return_all = TRUE, report = "aural_visit")
final_aural_visit = bind_rows(tray$insert,
                              tray$update)
dup_aural_visit = tray$duplicate

# survey
subset_aural_survey = gelled_aural %>%
  select(any_of(colnames(db_survey))) %>%
  distinct() %>%
  drop_na(survey_id)
tray = compare_for_staging(db_survey %>% collect(), subset_aural_survey, tbl_pkey('survey', mdc), return_all = TRUE, report = "aural_survey")
final_aural_survey = bind_rows(tray$insert,
                               tray$update)
dup_aural_survey = tray$duplicate

# aural
subset_aural = gelled_aural %>%
  select(any_of(colnames(db_aural))) %>%
  distinct() %>%
  drop_na(aural_id)
tray = compare_for_staging(db_aural %>% collect(), subset_aural, tbl_pkey('aural', mdc), return_all = TRUE, report = "aural")
final_aural = bind_rows(tray$insert,
                        tray$update)
dup_aural = tray$duplicate

subset_aural_visit %>%
  get_dupes(visit_id)

```

### Stage and commit aural tables

```{r}

# begin transaction temp
dbBegin(dbcon)

tryCatch(
  {
    temp_aural_visit = stage_to_temp(dbcon, db_visit, final_aural_visit)
    temp_aural_survey = stage_to_temp(dbcon, db_survey, final_aural_survey)
    temp_aural = stage_to_temp(dbcon, db_aural, final_aural)
    
    # Commit the transaction if successful
    dbCommit(dbcon)
    print("Transaction successful!")
    
  }, error = function(e) {
    # Rollback in case of error
    dbRollback(dbcon)
    message("Transaction failed: ", e$message)
  })


# begin upsert transaction
dbBegin(dbcon)

tryCatch(
  {
    pointer = tbl(dbcon, temp_aural_visit)
    rows_upsert(db_visit, pointer, by=tbl_pkey("visit", mdc), in_place=TRUE)
    
    pointer = tbl(dbcon, temp_aural_survey)
    rows_upsert(db_survey, pointer, by=tbl_nkey("survey", mdc), in_place=TRUE)
    
    pointer = tbl(dbcon, temp_aural)
    rows_upsert(db_aural, pointer, by=tbl_pkey("aural", mdc), in_place=TRUE)
    
    # Commit the transaction if successful
    dbCommit(dbcon)
    print("Transaction successful!")
    
  }, error = function(e) {
    # Rollback in case of error
    dbRollback(dbcon)
    message("Transaction failed: ", e$message)
  })

```


## VES chain
- ves / survey / visit / site / region / location

### Reload survey & visit
```{r}
db_aural = tbl(dbcon, Id("survey_data", "aural"))
db_survey = tbl(dbcon, Id("survey_data", "survey"))
db_visit = tbl(dbcon, Id("survey_data", "visit"))
```



### Unify ves data
```{r}
unified_ves = clean_ves_obs %>%
  full_join(clean_ves_survey, by = c("fulcrum_parent_id" = "fulcrum_id")) %>%
  select(-fulcrum_parent_id) %>%
  left_join(clean_survey_info, by = c("site", "date")) %>%
  left_join(db_site %>%
              select(tbl_keys("site", mdc)) %>%
              collect(),
            by = tbl_nkey("site", mdc)) %>%
  left_join(db_visit %>%
              select(tbl_keys("visit", mdc)) %>%
              collect(),
            by = tbl_nkey("visit", mdc)) %>%
  left_join(db_survey %>%
              select(tbl_keys("survey", mdc)) %>%
              filter(!is.na(visit_id)) %>%
              collect(),
            by = tbl_nkey("survey", mdc))

if (any(is.na(unified_ves$site_id))) {
  stop("unknown ves sites found. More rigorous coding needed :)")
}

peace = unified_ves %>%
  distinct(site, date, time_of_day, detection_type, start_time, end_time, comments_survey) %>%
  get_dupes(site, date, time_of_day, detection_type)

```

### Gel ves data
```{r}
gelled_ves = unified_ves %>%
  select(-comments_visit) %>% # update at end
  group_by_at(tbl_nkey("visit", mdc)) %>%
  mutate(visit_id = ifelse(is.na(visit_id), UUIDgenerate(), visit_id)) %>%
  ungroup() %>%
  group_by_at(tbl_nkey("survey", mdc)) %>%
  mutate(survey_id = ifelse(is.na(survey_id), first(fulcrum_id), survey_id),
         survey_id = ifelse(is.na(survey_id), UUIDgenerate(), survey_id)) %>%
  ungroup()
```

### 5 - Subset final ves tables

```{r}
# visit
subset_ves_visit = gelled_ves %>%
  select(any_of(colnames(db_visit))) %>%
  distinct() %>%
  drop_na(visit_id)
tray = compare_for_staging(db_visit %>% collect(), subset_ves_visit, tbl_pkey('visit', mdc), return_all = TRUE, report = "ves_visit")
final_ves_visit = bind_rows(tray$insert,
                             tray$update)

# survey
subset_ves_survey = gelled_ves %>%
  select(any_of(colnames(db_survey))) %>%
  distinct() %>%
  drop_na(survey_id)
tray = compare_for_staging(db_survey %>% collect(), subset_ves_survey, tbl_pkey('survey', mdc), return_all = TRUE, report = "ves_survey")
final_ves_survey = bind_rows(tray$insert,
                             tray$update)

# aural
subset_ves = gelled_ves %>%
  select(any_of(colnames(db_ves))) %>%
  distinct() %>%
  drop_na(ves_id)
tray = compare_for_staging(db_ves %>% collect(), subset_ves, tbl_pkey('ves', mdc), return_all = TRUE, report = "ves")
final_ves = bind_rows(tray$insert,
                      tray$update)

```

### Stage and commit aural tables

```{r}

# begin transaction temp
dbBegin(dbcon)

to_upsert = list()

tryCatch(
  {
    temp_ves_visit = stage_to_temp(dbcon, db_visit, final_ves_visit)
    to_upsert[["visit"]] = temp_ves_visit
    temp_ves_survey = stage_to_temp(dbcon, db_survey, final_ves_survey)
    to_upsert[["survey"]] = temp_ves_survey
    temp_ves = stage_to_temp(dbcon, db_ves, final_ves)
    to_upsert[["ves"]] = temp_ves
    
    # Commit the transaction if successful
    dbCommit(dbcon)
    print("Transaction successful!")
    
  }, error = function(e) {
    # Rollback in case of error
    dbRollback(dbcon)
    to_upsert = list()
    message("Transaction failed: ", e$message)
  })


# begin upsert transaction
dbBegin(dbcon)

tryCatch(
  {
    pointer = tbl(dbcon, temp_ves_visit)
    rows_upsert(db_visit, pointer, by=tbl_pkey("visit", mdc), in_place=TRUE)
    
    pointer = tbl(dbcon, temp_ves_survey)
    rows_upsert(db_survey, pointer, by=tbl_pkey("survey", mdc), in_place=TRUE)
    
    pointer = tbl(dbcon, temp_ves)
    rows_upsert(db_ves, pointer, by=tbl_pkey("aural", mdc), in_place=TRUE)
    
    # Commit the transaction if successful
    dbCommit(dbcon)
    print("Transaction successful!")
    
  }, error = function(e) {
    # Rollback in case of error
    dbRollback(dbcon)
    message("Transaction failed: ", e$message)
  })



```

## Reload survey & visit
```{r}
db_survey = tbl(dbcon, Id("survey_data", "survey"))
db_visit = tbl(dbcon, Id("survey_data", "visit"))
```

## Capture chain
- capture / survey / visit / site / region / location

```{r}

unified_sample =  clean_sample_obs %>% 
  full_join(clean_sample_processing, by= c("fulcrum_parent_id" = "fulcrum_id")) %>%
  unite("comments_sample", c("comments_sample.x", "comments_sample.y"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(-fulcrum_id,
         -fulcrum_parent_id)

unified_capture = clean_capture_obs %>%
  full_join(clean_capture_survey, by = c("fulcrum_parent_id" = "fulcrum_id")) %>%
  select(-fulcrum_parent_id) %>%
  mutate(temp_capture_id = fulcrum_id) %>%
  # full_join(unified_sample, by=c("site", "date", "bag_id")) %>%
  # mutate(species_capture = coalesce(species_capture.y, species_capture.x),
  #        survey_time = coalesce(survey_time.x, survey_time.y)) %>%
  # select(-survey_time.x,
  #        -survey_time.y,
  #        -species_capture.x,
  #        -species_capture.y) %>%
  # unite("comments_capture", c("comments_capture", "comments_sample"), sep=",", remove = TRUE, na.rm = TRUE) %>%
  left_join(clean_survey_info, by = c("site", "date")) %>%
  select(-fulcrum_id) %>%
  left_join(db_site %>%
              select(tbl_keys("site", mdc)) %>%
              collect(),
            by = tbl_nkey("site", mdc)) %>%
  left_join(db_visit %>%
              select(tbl_keys("visit", mdc)) %>%
              collect(),
            by = tbl_nkey("visit", mdc)) %>%
  left_join(db_survey %>%
              select(tbl_keys("survey", mdc)) %>%
              filter(!is.na(visit_id)) %>%
              collect(),
            by = tbl_nkey("survey", mdc))


# QA/QC

# exploration
sample_unmatched = unified_sample %>%
  anti_join(unified_capture, by=c("site", "date", "bag_id")) %>%
  # select(site, date, bag_id, species_capture, sample_id) %>%
  mutate(capture_id = as.character(NA)) %>%
  filter(!is.na(bag_id))

capture_unmatched = unified_capture %>%
  anti_join(unified_sample, by=c("site", "date", "bag_id")) %>%
  # select(site, date, bag_id, species_capture, capture_id) %>%
  mutate(sample_id = as.character(NA)) %>%
  filter(!is.na(bag_id))

sample_capture_unmatched = bind_rows(capture_unmatched, sample_unmatched) %>%
  arrange(site, date, bag_id) %>%
  group_by(site, date) %>%
  mutate(temp_id = cur_group_id()) %>%
  ungroup() %>%
  select(site, date, bag_id, species_capture, capture_id, sample_id, start_time, end_time, observer_capture, processor, observers_survey, comments_capture, comments_sample,)

write_csv(sample_capture_unmatched, here("staging", "sample_campture_unmatched.csv"))

test_site = "tuttle_pond"
test_date = "2024-07-08"

peace = unified_sample %>%
  filter(site == test_site,
         date == test_date) %>%
  arrange(bag_id)

train = unified_capture %>%
  filter(site == test_site,
         date == test_date) %>%
  arrange(bag_id)

```

# Gelled capture

```{r}

# compare db and constructed columns for anything weird.
# peace = compare_df_cols(db_capture %>%
#                           filter(FALSE) %>%
#                           collect(), unified_capture)
# peace = compare_df_cols(db_survey %>%
#                           filter(FALSE) %>%
#                           collect(), unified_capture)
# peace = compare_df_cols(db_visit %>%
#                           filter(FALSE) %>%
#                           collect(), unified_capture)

gelled_capture = unified_capture %>%
  select(-comments_visit) %>% # update at end
  group_by_at(tbl_nkey("visit", mdc)) %>%
  mutate(visit_id = ifelse(is.na(visit_id), UUIDgenerate(), visit_id)) %>%
  ungroup() %>%
  group_by_at(tbl_nkey("survey", mdc)) %>%
  mutate(survey_id = ifelse(is.na(survey_id), UUIDgenerate(), survey_id)) %>%
  ungroup()

```

### 5 - Subset final capture tables

```{r}
# visit
subset_capture_visit = gelled_capture %>%
  select(any_of(colnames(db_visit)))

compare
# survey
subset_capture_survey = gelled_capture %>%
  select(any_of(colnames(db_survey)))

# aural
subset_capture = gelled_capture %>%
  select(any_of(colnames(db_capture)))

```

## Merge unique visits include site

### Merge all site visits

- pull unique visits from survey_info, survey_acoustic, survey_capture, survey_edna, and survey_ves
- spread site_info comments across all corresponding visits

```{r}

# site info comments
temp_visit_comments <- raw_survey_info %>% 
  select(site, date, visit_comments)

mid_visit <- bind_rows(raw_survey_info, raw_survey_acoustic, raw_survey_capture, raw_survey_ves) %>% 
  select(date, site, survey_time) %>%
  filter(!is.na(site)) %>%  # drop observations with NA site
  group_by(date, site) %>%
  mutate(temp_id = cur_group_id()) %>% 
  filter(!duplicated(temp_id)) %>%
  left_join(temp_visit_comments, by = c("site", "date")) %>% # merge comments across all visits
  select(!temp_id) %>% 
  ungroup()

```

### Pull site_id f.key (uuid) from site table of DB

```{r}

site_key = db_site %>%
  select(site, site_id) %>%
  collect()

```

### Coalesce with DB
- Join with site_id
- Join with visit_db
- create visit_id (uuid) on visit table where doesnt yet exist
- coalesce comments, prioritizing new data

```{r}

# confirm visit does not already exist
final_visit = mid_visit %>%
  left_join(site_key, by = "site") %>%
  left_join(db_visit %>% collect(), by = nkey("visit", mdc)) %>%
  mutate(visit_id = map_chr(visit_id, ~ UUIDgenerate_if_NA(.))) %>% # generate UUID only if not already present
  mutate(visit_comments = coalesce(visit_comments.x, visit_comments.y)) %>% # prioritize new site comments in case updated
  select(-site,
         -visit_comments.x,
         -visit_comments.y)

# test to make sure column names are the same, nothing is missing

# test to make sure datatypes are good

# handle possible new sites
if (any(is.na(final_visit$site_id))) {
  warningCondition("New or unknown sites found in incoming data. Troubleshoot.")
  # do we want this new site in the database?
  #   yes: generate new uuid and update db site table.
  #   no: drop and incorporate relevant filter to prevent recurrence
}

```

### Append to visit table

```{r}


warningCondition("Visit append commented out. Rewrite at end as single transaction.")
# dbAppendTable(dbcon, "visit", fin_visit)  # append at end in transaction
  

```

## Merge all survey data into common survey table

### Massage Survey data date and survey_time

```{r}

mid_surv_capture <- raw_survey_info %>%
  left_join(raw_survey_capture, by = c("site", "date")) %>%
  select(!c(fulcrum_id.x,
            fulcrum_id.y,
            observer,
            observer_other,
            site_other.x,
            site_other.y,
            start_time.x,
            end_time.x,
            survey_time.y,
            air_temperature_measurement_time,
            water_temperature_measurement_time)) %>%
  unite(observer, c("observers", "other_observers"), sep=",", na.rm = T) %>% 
  rename(start_time = start_time.y,
         end_time = end_time.y,
         survey_time = survey_time.x)

mid_surv_ves <- raw_survey_info %>% 
  left_join(raw_survey_ves, by = c("site", "date")) %>% 
  select(!c(fulcrum_id.x,
            fulcrum_id.y,
            observer,
            observer_other,
            site_other,
            start_time.x,
            end_time.x,
            survey_time.y,
            air_temperature_measurement_time,
            water_temperature_measurement_time)) %>% 
  mutate(detection_type = "visual") %>% 
  unite(observer, c("observers", "other_observers"), sep=",", na.rm = T) %>% 
  rename(start_time = start_time.y,
         end_time = end_time.y,
         survey_time = survey_time.x)

(raw_survey_acoustic)

mid_surv_aural <- raw_survey_info%>% 
  select(!c(fulcrum_id,
            site_other,
            start_time,
            end_time,
            survey_time)) %>% 
  mutate(detection_type = "aural")

# all surveys across survey types
surv_info <- bind_rows(mid_surv_capture, mid_surv_ves, mid_surv_aural)

# unique surveys only... looks like this is not used?
# mid_unique_survey <- bind_rows(survey_acoustic, survey_capture, survey_ves) %>% 
#   select(!c(fulcrum_id, observer, observer_other, acoustic_survey_comments)) %>% 
#   full_join(surv_info, by = c("site", "date", "detection_type")) %>% 
#   select(!c(site_other, air_temperature_measurement_time, water_temperature_measurement_time, end_time.y,
#             start_time.y, observers, other_observers, survey_time.x, survey_time.y)) %>% 
#   rename(start_time = start_time.x,
#          end_time = end_time.x) %>% 
#   mutate(survey_time = "Night") %>% # confirm all surveys are night surveys...
#   unite(survey_comments, c("survey_comments.x", "survey_description.x", "survey_comments.y", "survey_description.y"),
#         sep = ",", na.rm=T)

unique_survey <- surv_info %>% 
  group_by(site, date, detection_type) %>% 
  mutate(start_time = as_hms(mean(start_time)), # clean times
         end_time = as_hms(mean(end_time))) %>% 
  select(!c("water_temperature_measurement_time", "air_temperature_measurement_time", "other_observers", "observers")) %>% 
  unite(survey_comments, c("survey_comments", "sampling_event_comments", "survey_description"), na.rm = T, sep = ",") %>% 
  rename(wind = wind_conditions,
         sky = sky_conditions,
         relative_humidity_percent = humidity,
         pressure_psi = pressure, # need to confirm units
         wind_speed_m_s = wind_speed_ms,
         air_temp_c = air_temperature_c,
         dissolved_o2_percent = dissolved_oxygen,
         tds_ppm = total_dissolved_solids, # need to confirm units
         water_temp_c = water_temperature_c,
         p_h = ph) %>% # clean column names
  mutate(survey_time = str_to_lower(survey_time),
         site = str_to_lower(str_replace_all(site, "-", "_")),
         site = str_replace_all(site, " ", "_"),
         survey_time = if_else(is.na(survey_time), "night", survey_time),
         temp_id = cur_group_id()) %>% 
  filter(!duplicated(temp_id)) %>% 
  select(!temp_id) %>% 
  ungroup()



```

### Pull visit pkey from unique table above

```{r}

surv_fkey <- unique_visits_fkey %>% 
  select(date, visit_id, site)

# duplicates passed from visit_id generation

```

### Join visit pkey into surv fkey

```{r}

unique_survey_fkey <- unique_survey %>% 
  full_join(surv_fkey, by = c("date", "site")) %>% 
  mutate(p_h = if_else(p_h == 0.00, NA, p_h)) %>% 
  group_by(site, date, detection_type) %>% 
  mutate(survey_id = UUIDgenerate(output = c("uuid"))) %>% # move to end, after antijoin wtih survey table
  filter(!duplicated(survey_id)) %>% # this should not be needed once above corrections made
  mutate(duration_min = if_else(end_time < start_time,
                            as_hms(86400) - start_time + end_time,
                            end_time - start_time),
         duration_min = duration_min/60,
         duration_min = str_remove(duration_min, " secs"),
         duration_min  = round(as.numeric(duration_min), 2)) %>%  # why rounding duration to 2? Put in data dictionary description
  group_by(date, site) %>% 
  mutate(survey_time = if_else(is.na(survey_time), "night", survey_time)) %>% 
  select(!c(conductivity_us))

```

### final survey table

```{r}

fin_survey <- unique_survey_fkey %>% 
  ungroup() %>% 
  select(!c(date, survey_time, site)) %>% 
  rename(duration_minutes = duration_min) %>% # define properly above and delete
  mutate(duration_minutes = as.integer(duration_minutes))# define properly above and delete

warningCondition("Survey append commented out. Rewrite as single transaction.")  
# dbAppendTable(dbcon, "survey", fin_survey) # don't drop fulcrum_id until here.

```

## Capture table

### merge and clean capture tables

```{r}
#cap_col <- read_csv(here("clean_tables", "capture.csv"))

mid_cap <- survey_info %>% 
  left_join(survey_capture, by = c("site" , "date")) %>% # could we do this on fin_survey or similar, to carry forward all names and ids? Need fulcrum_id though.
  select(fulcrum_id.y, detection_type, date, site, survey_time.x) %>% 
  rename(fulcrum_id = fulcrum_id.y,
         survey_time = survey_time.x) %>% 
  left_join(capture_obs, by = c("fulcrum_id" = "fulcrum_parent_id")) %>% # revisit later after cleaning above. Should not need left join, full join should return same and catch any errors if not
  select(detection_type.x, date, site, survey_time, detection_type.x, body_temperature, bag_id, species_capture, 
         time_of_capture, microhabitat_type, microhabitat_wet, microhabitat_temperature, amphibian_comments)

mid_samp_proc <- samp_proces %>% 
  left_join(samp_procces_obs, by= c("fulcrum_id" = "fulcrum_parent_id")) %>% # full join? to catch errors
  select(!c(fulcrum_id,
            fulcrum_id.y)) 

# separate sample negative controls
neg_controls <- mid_samp_proc %>% 
  filter(species_capture == "Negative Control") %>% 
  select(!c(processor_other,
            sex_other,
            survey_comments,
            life_stage_other,
            c(species_capture_other:body_mass))) %>%  # explicitly drop (or explicitly select), not robust to change in column order
  rename(site = location) %>% 
  mutate(species_capture = str_to_lower(str_replace_all(species_capture, " ", "_")),
         survey_time = str_to_lower(survey_time),
         site = str_to_lower(str_replace_all(site, " ", "_")))

# drop sample negative controls
mid_samp_proc <- mid_samp_proc %>% 
  filter(!species_capture == "Negative Control") %>% 
  select(!species_capture_other)

unique_cap <- mid_samp_proc %>% 
  left_join(mid_cap, by = c("location"= "site", "date", "bag_id")) %>% # any chance of a mid_cap with no samps, but relevant data? If so, full join? Or bind_rows.
  select(!c(survey_time.y, species_capture.y, life_stage_other, sex_other,
            survey_comments)) %>% 
  rename(detection_type = detection_type.x,
         survey_time = survey_time.x,
         species_capture = species_capture.x) %>% 
  unite(processor, c("processor", "processor_other"), na.rm = T, sep = "") %>% 
  unite(capture_comments, c("amphibian_comments", "capture_comments"), na.rm = T,
        sep = ", ") %>%
  mutate(amp_id = if_else(capture_mark_recapture %in% ("cf358e11-d6da-4637-af56-c384d683e6fb"), "Pe_AMP00000", amp_id)) # to what does this id correspond?



```

### generate capture_id

```{r}

cap_fkey <- unique_survey_fkey %>%
  select(site, date, detection_type, survey_time, survey_id)


unique_cap_fkey <- unique_cap %>% 
  mutate(detection_type = "capture",
         capture_id = UUIDgenerate(n = n())) %>% 
  left_join(cap_fkey, by = c("site", "date", "detection_type", "survey_time"))
  

```

### final capture table

#### empty column search

## create empty columns in DB which are new to this data set

```{r}

final_cap <- unique_cap_fkey %>% 
  select(!c(survey_time, detection_type, site, date)) %>% 
  rename(microbiome_swab_id = microbiome_id,
         sierra_bd_swab_id = bd_swab_id_sv) %>%
  mutate(across(c(bd_swab_id:genetic_id), ~ifelse(str_detect(., "00000"), NA, .))) %>% 
  select(!c(sierra_bd_swab_id, bacterial_swab_id_foundations, location_other))


q_col <- "SELECT *
          FROM capture
          LIMIT 1;"

col_names <- dbGetQuery(dbcon, q_col) %>%
  colnames()

db_cols <- final_cap %>%
  colnames()

missing_cols <- setdiff(db_cols, col_names) %>%
  print() %>%
  as.character()


add_col_q <- paste0("alter table capture
                  add ", missing_cols[1]," varchar;")

dbExecute(dbcon, add_col_q)

add_col_q <- paste0("alter table capture
                  add ", missing_cols[2]," varchar;")

dbExecute(dbcon, add_col_q)



dbAppendTable(dbcon, "capture", final_cap)

```

## VES

### clean and merged ves data

```{r}

ves_c <- read_csv(here("clean_tables", "ves.csv"))

mid_ves <- survey_ves %>% 
  left_join(ves_obs, by = c("fulcrum_id" = "fulcrum_parent_id")) %>% 
  select(!c(fulcrum_id, detection_type.x, fulcrum_id.y, fulcrum_record_id, start_time, end_time,
            survey_description)) %>% 
  rename(detection_type = detection_type.y)


unique_ves <- mid_ves %>% 
  unite(observer, c("observer", "observer_other"), na.rm = T, sep = "") %>% 
  unite(species_ves, c("species_ves", "species_ves_other"), na.rm = T, sep = "") %>% 
  rename(ves_comments = comments_ves,
         count = count_ves)


```

### populate VES fkey

```{r}

ves_fkey <- unique_survey_fkey %>% 
  select(site, date, detection_type, survey_time, survey_id)

unique_ves_fkey <- unique_ves %>% 
  left_join(ves_fkey, by = c("site", "date", "detection_type", "survey_time")) %>% 
  mutate(ves_id = UUIDgenerate(n = n()),
         species_ves = if_else(species_ves == "", NA, species_ves)) %>% 
  drop_na(species_ves)



```

### final ves table

```{r}

final_ves <- unique_ves_fkey %>% 
  select(!c(site, date, survey_time, detection_type))

dbAppendTable(dbcon, "ves", final_ves)

```

## aural

### clean and merge arual

```{r}

aural_cols <- read_csv(here("clean_tables", "aural.csv"))


mid_aural <- survey_acoustic %>% 
  left_join(acoustic_obs, by = c("fulcrum_id" = "fulcrum_parent_id"))%>% 
  select(!c(fulcrum_id, detection_type.x, fulcrum_id.y, fulcrum_record_id, start_time, end_time,
            observer_other, species_acoustic_other, acoustic_survey_comments))

unique_aural <- mid_aural %>% 
  rename(detection_type = detection_type.y) %>% 
  mutate(species_acoustic = str_to_lower(str_replace_all(species_acoustic, " ", "_")),
         survey_time = str_to_lower(survey_time)) %>% 
  rename(species_aural = species_acoustic,
         aural_comments = acoustic_species_comments)
  


```

### populate aural fkey

```{r}

aural_fkey <- unique_survey_fkey %>% 
  select(site, date, detection_type, survey_time, survey_id)


unique_aural_fkey <- unique_aural %>% 
  mutate(detection_type = "aural",
         aural_id = UUIDgenerate(n = n())) %>% 
  left_join(aural_fkey, by = c("site", "date", "detection_type", "survey_time"))
  

```

### final aural table

```{r}

final_aural <- unique_aural_fkey %>% 
  select(!c(site, date, detection_type, survey_time))

# dbAppendTable(dbcon, "aural", final_aural)

```

## CMR table

```{r}

cmr_cols <- read_csv(here("clean_tables", "penn_cmr.csv"))

final_cmr <- cmr %>% 
  select(!c(species_other, location, species)) %>% 
  unite(cmr, c("cmr_id", "cmr_id_other"), na.rm = T, sep = "") %>% 
  rename(capture_mark_recapture = fulcrum_id,
         cmr_id = cmr)

dbAppendTable(dbcon, "cmr", final_cmr)

```
