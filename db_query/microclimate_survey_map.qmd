---
title: "microclimate_survey_pull"
format: html
---


```{r}
librarian::shelf(tidyverse, dbplyr, here, janitor, lubridate, rio, RPostgres, stringr, DBI, parsedate, uuid, hms, RIBBiTR-BII/ribbitrrr, plotly)
# librarian::shelf(RIBBiTR-BII/ribbitrrr, update_all = TRUE)

## Connect to DB
dbcon <- hopToDB("ribbitr")

```

table pointers
```{r}
# survey data
db_survey = tbl(dbcon, Id("survey_data", "survey"))
db_visit = tbl(dbcon, Id("survey_data", "visit"))

# microclimate data
db_ts_temp = tbl(dbcon, Id("microclimate_data", "ts_temperature"))
db_sensor = tbl(dbcon, Id("microclimate_data", "sensor"))
db_logger = tbl(dbcon, Id("microclimate_data", "logger"))
db_site = tbl(dbcon, Id("survey_data", "site"))
db_region = tbl(dbcon, Id("survey_data", "region"))
db_country = tbl(dbcon, Id("survey_data", "country"))
```

# define function
```{r}

microclimate_subset_presurvey = function(survey_data, buffer, time_series_pointer, time_sensitive = FALSE, output_timezone = NA) {
  
  
  
  # check data format
  if (is.data.frame(survey_data)) {
    data_cols = colnames(survey_data)
  } else {
    stop("survey_data format not recognized. Expected data frame.")
  }
  
  # time/date check
  if (time_sensitive) {
    # check for timestamp
    if ("start_timestamp_utc" %in% data_cols & "end_timestamp_utc" %in% data_cols) {
      # check format
      if (!all(c(class(survey_data$start_timestamp_utc) == c("POSIXct", "POSIXt"), class(survey_data$end_timestamp_utc) == c("POSIXct", "POSIXt")))) {
        stop("Unexpected format of 'start_timestamp' and 'end_timestamp' columns. Expected c('POSIXct', 'POSIXt')")
      }
    } else {
      stop("Required columns 'start_timestamp' and 'end_timestamp' not found in survey_data")
    }
  } else {
    # check for date
    if ("date" %in% data_cols) {
      # check format
      if (!is.Date(survey_data$date)) {
        stop("Unexpected format of 'date' column. Expected Date.")
      }
    } else {
      stop("Required column 'date' not found in survey_data")
    }
  }
  
  # check for site_id
  if ("site_id" %in% data_cols) {
    # check format
    if (!is.character(survey_data$site_id)) {
      stop("Unexpected format of 'site_id' column. Expected character.")
    }
  } else {
    stop("Required column 'site_id' not found in survey_data")
  }
  
  # check for survey_id
  if ("survey_id" %in% data_cols) {
    # check format
    if (!is.character(survey_data$site_id)) {
      stop("Unexpected format of 'site_id' column. Expected character.")
    }
  } else {
    stop("Required column 'site_id' not found in survey_data")
  }
  
    # parse buffer
  if (is.na(buffer)) {
    buffer = days(0)
  } else {
    if (!class(buffer) == "Period") {
      stop("'buffer' format not recognized. Expected lubridate 'Period'.")
    }
  }
  
  # build sites_present list
  sites_data = unique(sort(survey_data$site_id))
  
  sites_mc = db_logger %>%
    select(site_id) %>%
    distinct() %>%
    filter(site_id %in% sites_data) %>%
    pull(site_id)
  
  sites_present = intersect(sites_data, sites_mc)
  sites_absent = setdiff(sites_data, sites_mc)
  
  if (length(sites_absent != 0)) {
    warning(paste0("The following site_id's found in provided data have no associated microclimate loggers and will be ignored: ", paste(sites_absent, collapse = ", ")))
  }
  
  if (time_sensitive) {
    survey_start_end = data_ex %>%
      filter(site_id %in% sites_present) %>%
      mutate(start = start_timestamp_utc - buffer,
             end = start_timestamp_utc) %>%
      select(survey_id, site_id, start, end)
    
    time_var = "start_timestamp"
  } else {
    survey_start_end = data_ex %>%
      filter(site_id %in% sites_present) %>%
      mutate(start = date - buffer,
             end = date) %>%
      select(survey_id, site_id, start, end)
    
    time_var = "date"
  }
  
  invalid_start_end = survey_start_end %>%
    filter(is.na(start) | is.na(end)) %>%
    pull(survey_id)
  
  if (length(invalid_start_end) > 0) {
    warning(paste0("NA values for survey ", time_var, " for the following surveys:\n\t"),
            paste0(invalid_start_end, sep = "\n\t"),
            "\n")
  }
  
  survey_start_end_valid = survey_start_end %>%
    filter(!(survey_id %in% invalid_start_end))
  

  if (nrow(survey_start_end_valid) > 0) {
    # build single compound query to fetch all data (less expensive than hundreds of queries)
    message("Pulling data from server... ", appendLF = FALSE)
    # create filter expression for one row
    create_row_filter <- function(site_id, start, end) {
      expr(
        (site_id == !!site_id & 
           timestamp_utc >= !!start & 
           timestamp_utc <= !!end)
      )
    }
    
    # create full filter expression
    create_full_filter <- function(filter_df) {
      row_filters <- pmap(filter_df, create_row_filter)
      reduce(row_filters, ~ expr(!!.x | !!.y))
    }
    
    # Create filter
    full_filter <- create_full_filter(survey_start_end_valid %>%
                                        select(-survey_id))
    # fetch all data
    mc_data = time_series_pointer %>%
      left_join(db_sensor, by = "sensor_id") %>%
      left_join(db_logger, by = "logger_id") %>%
      filter(!!full_filter) %>%
      select(site_id,
             all_of(colnames(time_series_pointer))) %>%
      collect()
    message("done.")
    
    # map data to each survey
    message("Remapping data to surveys... ", appendLF = FALSE)
    mc_data_mapped = pmap_df(survey_start_end_valid,
                      function(survey_id, site_id, start, end) {
                        mc_data %>%
                          filter(site_id == site_id,
                                 timestamp_utc >= start,
                                 timestamp_utc <= end) %>%
                          mutate(survey_id = survey_id) %>%
                          select(-site_id)
                      })
    message("done.")
    
  } else {
    stop("No valid surveys for given parameters, query aborted.")
  }
  
  # join with metadata
  mc_meta = db_sensor %>%
    left_join(db_logger, by = "logger_id") %>%
    collect()
  
  mc_data_final = mc_data_mapped %>%
    left_join(mc_meta, by = "sensor_id") %>%
    select(survey_id,
           sensor_id,
           everything()) %>%
    mutate(timestamp_utc = force_tz(timestamp_utc,tzone = "UTC"))
  
  # reset to initial timezone
  if (!is.na(output_timezone) & time_sensitive) {
    mc_data_final = mc_data_final %>%
      mutate(timestamp_tz = with_tz(timestamp_utc, tzone = output_timezone))
  }
  
  return(mc_data_final)
  
}

```

# example dataset
```{r}
data_ex = db_survey %>%
  left_join(db_visit, by = "visit_id") %>%
  left_join(db_site, by = "site_id") %>%
  left_join(db_region, by = "region_id") %>%
  left_join(db_country, by = "country_id") %>%
  filter(date >= "2023-06-01",
         date <= "2023-08-01",
         region == "pennsylvania") %>%
  collect()

```

# call function
```{r}
test_1 = microclimate_subset_presurvey(data_ex, buffer = days(2), db_ts_temp, time_sensitive = FALSE, output_timezone = NA)
test_2 = microclimate_subset_presurvey(data_ex, buffer = days(14), db_ts_temp, time_sensitive = FALSE, output_timezone = NA)
test_3 = microclimate_subset_presurvey(data_ex, buffer = days(2), db_ts_temp, time_sensitive = TRUE, output_timezone = NA)
test_4 = microclimate_subset_presurvey(data_ex, buffer = days(2), db_ts_temp, time_sensitive = TRUE, output_timezone = "America/Los_Angeles")
```