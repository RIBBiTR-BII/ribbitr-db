---
title: "sierra_mhc"
author: "Cob Staines"
date: "2025-08-18"
output: html_document
---

# Sierra data query for Imani for Sierra MHC project

## spatial scope: aggregate to site (or population) level
## temporal scope: aggregate to year (using 1 visit per year where available)

## variables of interest
  * adult frog abundance (CMR & VES)
  * Bd infection load (median sample size, confidence intervals)
  * Bd prevalence (calculated prevalence, sample size, confidence interval)


# Connection setup
```{r}
librarian::shelf(tidyverse, dbplyr, here, RPostgres, DBI, janitor, lubridate, RIBBiTR-BII/ribbitrrr)

# connect to ribbitr database
dbcon <- hopToDB("ribbitr")
```

# define functions
```{r}
# fuzzy grouping for identifying survey periods in time
fuzzy_grouping = function(x, delta){
  # Make groups of x if differences are less than or equal to delta
  # 
  # Parameters
  # ----------
  # x : array of values to be grouped
  # delta : difference in value that defines a group
  
  
  if(length(x) > 1){
    
    run_ind = diff(x) <= delta
    grouping = array(NA, dim=length(run_ind + 1))
    grouping[1] = 1
    for(i in 1:length(run_ind)){
      
      if(run_ind[i] == FALSE | is.na(run_ind[i])){
        grouping[i + 1] = grouping[i] + 1
      }
      else{
        grouping[i + 1] = grouping[i]
      }
      
    }
  } else{
    grouping = 1
  }
  
  return(grouping)

}

# binomial confidence interval
wilson_ci = function(x, n, conf.level = 0.95) {
  p_hat <- x / n
  z <- qnorm(1 - (1 - conf.level) / 2)
  
  denominator <- 1 + (z^2 / n)
  centre_adjusted_probability <- p_hat + (z^2 / (2 * n))
  adjusted_standard_deviation <- sqrt((p_hat * (1 - p_hat) / n) + (z^2 / (4 * n^2)))
  
  lower_bound <- (centre_adjusted_probability - z * adjusted_standard_deviation) / denominator
  upper_bound <- (centre_adjusted_probability + z * adjusted_standard_deviation) / denominator
  
  return(c(lower_bound = lower_bound, upper_bound = upper_bound))
}

wilson_ci_lower = function(x, n, conf.level = 0.95) {
  ws = wilson_ci(x, n, conf.level)
  return(ws[1])
}

wilson_ci_upper = function(x, n, conf.level = 0.95) {
  ws = wilson_ci(x, n, conf.level)
  return(ws[2])
}

# normal confidence interval
normal_ci = function(x, conf.level = 0.95) {
  n <- length(x)
  mean_x <- mean(x)
  sd_x <- sd(x)
  
  alpha <- 1 - conf.level
  t_value <- qt(1 - alpha/2, df = n - 1)
  margin_error <- t_value * sd_x / sqrt(n)
  
  lower <- mean_x - margin_error
  upper <- mean_x + margin_error
  
  return(c(lower_bound = lower, upper_bound = upper))
}

normal_ci_lower = function(x, conf.level = 0.95) {
  no = normal_ci(x, conf.level)
  return(no[1])
}

normal_ci_upper = function(x, conf.level = 0.95) {
  no = normal_ci(x, conf.level)
  return(no[2])
}


```

# database table pointers
```{r}
db_bd = tbl(dbcon, Id("survey_data", "bd_qpcr_results"))
db_sample = tbl(dbcon, Id("survey_data", "sample"))
db_capture = tbl(dbcon, Id("survey_data", "capture"))
db_ves = tbl(dbcon, Id("survey_data", "ves"))
db_survey = tbl(dbcon, Id("survey_data", "survey"))
db_visit = tbl(dbcon, Id("survey_data", "visit"))
db_site = tbl(dbcon, Id("survey_data", "site"))
```

# sites of interest
```{r}
# sites of interest
## provided by Imani
## excludes momo, no site id
site_oi = data.frame(
  site = as.character(c(
    20199,
    20198,
    21081,
    21076,
    50783,
    72996,
    72336,
    72808,
    74281,
    10220,
    10206,
    10490,
    10487,
    11008,
    11009,
    50837,
    10055,
    10090,
    20170,
    20169)),
  name_ima = c(
    "Milestone",
    "Milestone",
    "Milestone",
    "Milestone",
    "Mulkey",
    "Conness",
    "Unicorn",
    "Unicorn",
    "Gallison",
    "Dusy",
    "Barrett",
    "Center",
    "Center",
    "Forester",
    "Forester",
    "Independence",
    "McGee",
    "Wanda",
    "KernPt",
    "KernPt"),
  population = as.character(c(
    20199,
    20198,
    21081,
    21076,
    50783,
    72996,
    72336,
    72336,
    74281,
    10220,
    10206,
    10490,
    10487,
    11008,
    11008,
    50837,
    10055,
    10090,
    20170,
    20169)))

site_oi = site_oi %>%
  left_join(db_site %>%
              select(site,
                     site_id,
                     site_elevation_m,
                     geographic_area,
                     site_utme,
                     site_utmn) %>%
              filter(site %in% site_oi$site) %>%
              collect(), by = "site")

colnames(site_oi)
```

# Visits of interest

Identify visits to sites of interest, grouping by survey period, defined as:
  * any group of visits to the same site with no more than 7 days between visit dates
```{r}
# visits of interest
visit_oi = db_visit %>%
  filter(site_id %in% site_oi$site_id,
         visit_status == "suitable") %>%
  select(visit_id,
         site_id,
         date,
         comments_visit) %>%
  collect() %>%
  left_join(site_oi, by = "site_id") %>%
  mutate(year = year(date)) %>%
  select(site,
         year,
         date,
         comments_visit,
         everything()) %>%
  arrange(site,
          date) %>%
  group_by(site, year) %>%
  mutate(survey_period = fuzzy_grouping(as.integer(date), 7)) %>% # consider surveys within a rolling 7 days to be within the same survey period
  ungroup()

colnames(visit_oi)
```

# Surveys of interest
contains all surveys for sites of interest, including multiple survey periods

```{r}
# join with survey table
survey_oi = db_survey %>%
  filter(visit_id %in% visit_oi$visit_id,
         detection_type %in% c("capture", "visual")) %>%
  select(detection_type,
         detection_subtype,
         survey_quality,
         description,
         comments_survey,
         number_observers,
         survey_id,
         visit_id) %>%
  collect() %>%
  mutate(detection_type = ifelse(detection_type == "capture",
                                 detection_subtype,
                                 detection_type)) %>%
  select(-detection_subtype) %>%
  right_join(visit_oi, by = "visit_id") %>%
  arrange(site,
          date,
          survey_period)

```

# Survey periods of interest

Selection criteria when more than 1 survey period available for a given & year:

1) greatest number of survey types (capture, ves, swab) within survey period
2) greatest mean survey_quality within survey period: good (3) > fair (2) > poor (1) > NA (0)
3) greatest number of surveys within survey period
4) randomly select one

* Note that this prioritizes using concurrent surveys between different detection types, but it is possible for some detection types for a given site/year to have different survey periods when concurrent surveys are not available.

** where more than 1 VES survey was conducted in a survey period (rare) the 1st survey is used.
```{r}
# set random seed for consistent selection
set.seed(877)

# calculate selection criteria
survey_oi_priority = survey_oi %>%
  mutate(survey_quality_score = case_match(survey_quality,
                                           "good" ~ 3,
                                           "fair" ~ 2,
                                           "poor" ~ 1,
                                           NA ~ 0,
                                           .default = NA)) %>%
  group_by(site,
           year) %>%
  mutate(period_count = n_distinct(survey_period)) %>%
  ungroup() %>%
  group_by(site,
           year,
           survey_period) %>%
   mutate(detection_type_count = n_distinct(detection_type),
         mean_survey_quality_score = mean(survey_quality_score),
         survey_count = n(),
         random_val = runif(1)) %>%
  ungroup()

# select survey periods for cmr
period_select_cmr = survey_oi_priority %>%
  filter(detection_type == "cmr") %>%
  distinct(site,
           year,
           survey_period,
           detection_type_count,
           mean_survey_quality_score,
           survey_count,
           random_val,
           detection_type) %>%
  arrange(site,
          year,
          survey_period,
          detection_type_count,
          mean_survey_quality_score,
          survey_count,
          random_val) %>%
  group_by(site,
           year) %>%
  slice_head(n = 1) %>%
  ungroup()

# select survey periods for swab
period_select_swab = survey_oi_priority %>%
  filter(detection_type == "swab") %>%
  distinct(site,
           year,
           survey_period,
           detection_type_count,
           mean_survey_quality_score,
           survey_count,
           random_val,
           detection_type) %>%
  arrange(site,
          year,
          survey_period,
          detection_type_count,
          mean_survey_quality_score,
          survey_count,
          random_val) %>%
  group_by(site,
           year) %>%
  slice_head(n = 1) %>%
  ungroup()

# select survey periods for visual
period_select_visual = survey_oi_priority %>%
  filter(detection_type == "visual") %>%
  distinct(site,
           year,
           survey_period,
           detection_type_count,
           mean_survey_quality_score,
           survey_count,
           random_val,
           detection_type) %>%
  arrange(site,
          year,
          survey_period,
          detection_type_count,
          mean_survey_quality_score,
          survey_count,
          random_val) %>%
  group_by(site,
           year) %>%
  slice_head(n = 1) %>%
  ungroup()

# bring selected periods together across detection types
period_select = bind_rows(period_select_cmr,
                          period_select_swab,
                          period_select_visual) %>%
  select(site,
         year,
         survey_period,
         detection_type) %>%
  rename(survey_period_select = survey_period)

# check for duplicates
dupes_period_select = get_dupes(period_select, site, year, detection_type)

# wider table for visual inspection of available surveys
period_select_wide = period_select %>%
  mutate(detection_type = paste0(detection_type, "_survey_period")) %>%
  pivot_wider(id_cols = c(site, year),
              names_from = detection_type,
              values_from = survey_period_select) %>%
  arrange(site,
          year)

# visually check selections where multiple periods present for a site/year, to see if any should be flagged
check_period_select = survey_oi_priority %>%
  left_join(period_select, by = c("site", "year", "detection_type")) %>%
  filter(period_count > 1) %>%
  select(site,
         year,
         survey_period,
         survey_period_select,
         detection_type,
         description,
         comments_survey,
         comments_visit,
         detection_type_count,
         mean_survey_quality_score,
         survey_count,
         random_val,
         everything()) %>%
  arrange(site,
          year,
          survey_period,
          detection_type)

# surveys selected using criteria, across all detection types
survey_select = survey_oi_priority %>%
  right_join(period_select, by = c("site", "year", "survey_period" = "survey_period_select", "detection_type")) %>%
  arrange(site,
          date,
          detection_type) %>%
  group_by(site,
           year,
           detection_type) %>%
  mutate(id = row_number()) %>%
  ungroup() %>%
  filter((detection_type == "visual" & id == 1) | detection_type %in% c("cmr", "swab"))

```

# adult frog abundance

## visual
visual detection per survey period (1 survey per survey period)

## cmr
cmr detection within survey period (across all surveys in survey period)

```{r}
# visual data pull
data_visual = survey_select %>%
  filter(detection_type == "visual") %>%
  select(site,
         date,
         survey_period,
         year,
         survey_id,
         visit_id,
         detection_type,
         comments_survey,
         comments_visit) %>%
  left_join(db_ves %>%
               filter(survey_id %in% survey_select$survey_id,
                      life_stage == "adult",
                      visual_animal_state != "dead") %>%
               select(count_ves,
                      ves_id,
                      survey_id) %>%
               collect(), by = "survey_id") %>%
  mutate(count_ves = ifelse(is.na(count_ves), 0, count_ves))

# visual abundance calc
abundance_visual = data_visual %>%
  group_by(site,
           year,
           date,
           ) %>%
  rename(date_ves = date) %>%
  summarise(adult_count_visual = sum(count_ves),
            .groups = "drop")

# cmr data pull
data_cmr = survey_select %>%
  filter(detection_type == "cmr") %>%
  select(site,
         date,
         survey_period,
         year,
         survey_id,
         visit_id,
         detection_type,
         comments_survey,
         comments_visit) %>%
  right_join(db_capture %>%
               filter(survey_id %in% survey_select$survey_id,
                     life_stage == "adult",
                     capture_animal_state != "dead") %>%
               select(cmr_id,
                      capture_id,
                      survey_id,
                      life_stage,
                      capture_animal_state) %>%
               collect(), by = "survey_id")

# cmr abundance calc
abundance_cmr = data_cmr %>%
  group_by(site,
           year) %>%
  summarise(date_cmr_first = first(date),
            cmr_days = n_distinct(date),
            adult_count_cmr = n_distinct(cmr_id),
            .groups = "drop")

# join visual and cmr abundance data
abundance_stats = abundance_visual %>%
  full_join(abundance_cmr, by = c("site", "year"))

```

# Bd stats
  * calculated for living adults only
## Bd prevalence
  * sample size (n)
  * prevalence (n infected / n)
  * prevalence confidence intervals (using wilson score, assuming binomial prevalence distribution)
## Bd load -- (sample size, median bd, confidence intervals)
  * median infection load (for positives only)
  * Bd load confidence intervals (assuming log-normal distribution of positive loads)

```{r}
# swab data pull
data_swab = survey_select %>%
  filter(detection_type == "swab") %>%
  select(site,
         date,
         survey_period,
         year,
         survey_id,
         visit_id,
         detection_type,
         comments_survey,
         comments_visit) %>%
  right_join(db_bd %>%
               inner_join(db_sample, by = "sample_id") %>%
               inner_join(db_capture, by = "capture_id") %>%
               filter(survey_id %in% survey_select$survey_id,
                     life_stage == "adult",
                     capture_animal_state != "dead") %>%
               select(detected,
                      bd_its1_copies_per_swab,
                      cmr_id,
                      capture_id,
                      survey_id,
                      life_stage,
                      capture_animal_state) %>%
               collect(), by = "survey_id")

# Bd prevalence & load calc
bd_stats = data_swab %>%
  group_by(site,
           year) %>%
  summarise(date_swab_first = first(date),
            swab_days = n_distinct(date),
            adult_swab_n = n(),
            adult_bd_prevalence = sum(detected) / n(),
            adult_bd_prevalence_ci_lower = wilson_ci_lower(sum(detected), n(), conf.level = 0.95),
            adult_bd_prevalence_ci_upper = wilson_ci_upper(sum(detected), n(), conf.level = 0.95),
            adult_positive_bd_load_median = median(bd_its1_copies_per_swab[detected]),
            adult_positive_bd_load_ci_lower = exp(normal_ci_lower(log(bd_its1_copies_per_swab[detected]), conf.level = 0.95)),
            adult_positive_bd_load_ci_upper = exp(normal_ci_upper(log(bd_its1_copies_per_swab[detected]), conf.level = 0.95)),
            .groups = "drop")
```

# combine & export data as one table
```{r}
# join abundance and Bd stats
data_out = abundance_stats %>%
  full_join(bd_stats, by = c("site", "year")) %>%
  arrange(site,
          year)

# save to csv
write.csv(data_out, here("staging", paste0("sierra_mhc_abundance_bd_stats_", today(), ".csv")))

```

# disconnect from database
```{r}
dbDisconnect(dbcon)
```